Relations Extraction
====================

5. [] Saliency Predictions (Tables are really important - especially if we want to make it practically useful !)
6. [] Cleanup (Maybe get table info if available from S2ORC - or check with PwC team)
1. [] Teacher Forcing (Use predicted Clusters as part of pseudo-relations to get more negative examples)
4. [] Saliency Predictions (Any more global features we can add?)
2. [] Saliency Predictions (Full End-to-End model using Longformer maybe)
9. [] Cleanup (Take a critical look at collected data, identify bad annotations and/or annotation artifacts)
3. [] Saliency Predictions (Explicit Structure Modelling of the paper)
5. [] Saliency Predictions (Frequency seems to be one of the determiners of Saliency)
7. [] Coreference (Direct coreference is pretty great , but no anaphora resolution or any other linguisticy things present, Also links to generic names)
8. [] Coreference (Put it back in End-to-End, although I am always a skeptic of utility of end-to-end approaches at long document level)
