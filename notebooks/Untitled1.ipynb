{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dygie.commands.generate_metrics import load_documents, update_documents_with_clusters, update_documents_with_spans, load_jsonl\n",
    "from collections import namedtuple\n",
    "\n",
    "from collections import namedtuple\n",
    "def convert(dictionary):\n",
    "    return namedtuple('GenericDict', dictionary.keys())(**dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = load_documents('../model_data/pwc_split_on_sectioned/train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = []\n",
    "import re\n",
    "for d in train_documents :\n",
    "    for e in train_documents[d]['ner'] :\n",
    "        ner.append(re.sub(r'\\W+', '', \"\".join(train_documents[d]['words'][e[0]:e[1]])))\n",
    "ner = set(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36810"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Exact F1 &  Exact P &  Exact R &  Soft F1 &  Soft P &  Soft R \\\\\n",
      "\\midrule\n",
      "Method   &     0.784 &    0.779 &    0.789 &    0.808 &   0.803 &   0.813 \\\\\n",
      "Task     &     0.707 &    0.705 &    0.709 &    0.739 &   0.738 &   0.741 \\\\\n",
      "Metric   &     0.741 &    0.741 &    0.741 &    0.770 &   0.769 &   0.771 \\\\\n",
      "Material &     0.562 &    0.553 &    0.570 &    0.602 &   0.591 &   0.613 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "macro_p             0.146962\n",
      "macro_r             0.389234\n",
      "macro_overlap_p     0.338188\n",
      "macro_overlap_r     0.624775\n",
      "macro_f1            0.213364\n",
      "macro_overlap_f1    0.438836\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents('../model_data/pwc_split_on_sectioned/dev.jsonl')\n",
    "documents = update_documents_with_spans(documents, '../outputs/dev_outputs/spans.jsonl', convert({'gold' : False}))\n",
    "documents = update_documents_with_clusters(documents, '../outputs/dev_outputs/clusters.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for d in documents :\n",
    "    s.append(len(documents[d]['coref']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.454545454545454"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s)/len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02567fd428a675ca91a0c6786f47f3e35881bcbd\n",
      "{'Age_Estimation', 'MORPH_Album2', 'MAE', 'ChaLearn_2015', 'DLDL', 'VGG-Face'}\n",
      "{'DLDL', 'Age_Estimation', 'ChaLearn_2015', 'MAE'}\n",
      "====================\n",
      "02b3d1d162080d9aefd3fc30a0bcc9a843073b5d\n",
      "{'LSTM-8192-1024___CNN_Input', 'LSTM-8192-1024', 'CNN_Input', 'One_Billion_Word', 'Language_Modelling'}\n",
      "{'One_Billion_Word'}\n",
      "====================\n",
      "0398552184f80db111e9c28bf533b395f233ac00\n",
      "{'Self-paced_curriculum_learning', 'Weakly_Supervised_Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'PASCAL_VOC_2007', 'Weakly_Supervised_Object_Detection'}\n",
      "====================\n",
      "05d2700846c0323f79c1344aca5333994c7c03a5\n",
      "{'swb_hub_500_WER_fullSWBCH', '_model_M_', 'VGG', 'Speech_Recognition', 'CH__N-gram', 'Percentage_error', 'LSTM_acoustic_model_trained_on_SWB', 'NNLM_language_model', 'RNN', 'Switchboard___Hub500', 'RNN___VGG___LSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram____model_M____NNLM_language_model'}\n",
      "{'Percentage_error', 'Switchboard___Hub500', 'Speech_Recognition', 'swb_hub_500_WER_fullSWBCH'}\n",
      "====================\n",
      "0626908dd710b91aece1a81f4ca0635f23fc47f3\n",
      "{'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'Inception_V3', 'Image_Classification'}\n",
      "{'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'Inception_V3', 'Image_Classification'}\n",
      "====================\n",
      "0678a8abea82793993cd89383319da75f6dc4be3\n",
      "{'MAP', 'ProNet', 'COCO', 'Weakly_Supervised_Object_Detection'}\n",
      "{'MAP', 'ProNet', 'COCO'}\n",
      "====================\n",
      "081531984770a74e87dbd68907061b4b0f3631bf\n",
      "{'Vid4_-_4x_upscaling', 'MOVIE', 'SSIM', 'VESPCN', 'Video_Super-Resolution', 'PSNR', 'bicubic'}\n",
      "{'Vid4_-_4x_upscaling', 'MOVIE', 'SSIM', 'Video_Super-Resolution', 'PSNR'}\n",
      "====================\n",
      "0834e74304b547c9354b6d7da6fa78ef47a48fa8\n",
      "{'Node_Classification', 'LINE', 'Wikipedia', 'Macro-F1'}\n",
      "{'Node_Classification', 'Macro-F1'}\n",
      "====================\n",
      "0a3381f0432c5cfe491c718349d7a44e5814592c\n",
      "{'Bi-LSTM', 'CoNLL-2014_A2', 'FCE', 'Grammatical_Error_Detection', 'CoNLL-2014_A1'}\n",
      "{'CoNLL-2014_A1', 'FCE', 'Grammatical_Error_Detection'}\n",
      "====================\n",
      "0a6c36de8726b6feaab586046ddc1d1a008f44f9\n",
      "{'Pedestrian_Detection', 'Checkerboards_', 'Caltech', 'Reasonable_Miss_Rate'}\n",
      "{'Pedestrian_Detection', 'Caltech', 'Reasonable_Miss_Rate'}\n",
      "====================\n",
      "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e\n",
      "{'CoNLL_2003__English_', 'Multi-Task', 'Dependency_Parsing', 'POS', 'Accuracy', 'CCG_Supertagging', 'Ontonotes_v5__English_', 'Penn_Treebank', 'Named_Entity_Recognition__NER_', 'CCGBank', 'CVT'}\n",
      "{'Penn_Treebank', 'Accuracy'}\n",
      "====================\n",
      "0dc9eb7d17f2def56ad930945f2521653f04c3fa\n",
      "{'PPL', 'Number_of_params', 'Sparse_Non-Negative', 'One_Billion_Word', 'Language_Modelling'}\n",
      "{'Sparse_Non-Negative', 'PPL', 'One_Billion_Word'}\n",
      "====================\n",
      "107010b7f2abe3c0c9df62bcef35eb77f6fc76df\n",
      "{'DANN', 'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "{'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "====================\n",
      "1130d8fdd931225c2d7563c3808367726cfa1c3a\n",
      "{'PixelGAN_Autoencoders', 'Unsupervised_MNIST', 'MNIST', 'Unsupervised_image_classification'}\n",
      "{'PixelGAN_Autoencoders', 'MNIST', 'Unsupervised_image_classification'}\n",
      "====================\n",
      "11356cd6bb0f2776a88cd584ff108470414c6594\n",
      "{'SSCN'}\n",
      "set()\n",
      "====================\n",
      "11da0c54ba904a1cb31a09d10da55f73e8825c61\n",
      "{'Natural_Language_Inference', '__Test_Accuracy', '300D_Tree-based_CNN_encoders', 'SNLI'}\n",
      "{'Natural_Language_Inference', 'SNLI'}\n",
      "====================\n",
      "1235dd37312cb20aced0e97d953f6379d8a0c7d4\n",
      "{'BiMPM', 'V-SNLI', 'Accuracy', 'Natural_Language_Inference', 'V-BiMPM'}\n",
      "{'Accuracy', 'V-SNLI'}\n",
      "====================\n",
      "14318685b5959b51d0f1e3db34643eb2855dc6d9\n",
      "{'Inception_V1', 'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'MAP', 'Image_Classification', 'Object_Detection'}\n",
      "{'MAP', 'Image_Classification', 'Top_1_Accuracy', 'Top_5_Accuracy'}\n",
      "====================\n",
      "16051bbe3a7f7c77a952ebf76722ea655e8906ca\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'FAFR_', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR', 'FARF_'}\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'PSNR', 'FARF_'}\n",
      "====================\n",
      "160563abbd75265b19afc8b4169bab9e1eb33d97\n",
      "{'MLDoc_Zero-Shot_English-to-Spanish', 'BUCC_French-to-English', 'MLDoc_Zero-Shot_English-to-German', 'Accuracy', 'Massively_Multilingual_Sentence_Embeddings', 'XNLI_Zero-Shot_English-to-German', 'Cross-Lingual_Document_Classification', 'Cross-Lingual_Bitext_Mining', 'XNLI_Zero-Shot_English-to-French', 'BiLSTM', 'MLDoc_Zero-Shot_English-to-French', 'BUCC_German-to-English', 'Cross-Lingual_Natural_Language_Inference', 'XNLI_Zero-Shot_English-to-Spanish'}\n",
      "{'BUCC_French-to-English', 'Accuracy', 'Massively_Multilingual_Sentence_Embeddings', 'XNLI_Zero-Shot_English-to-German', 'XNLI_Zero-Shot_English-to-French', 'BUCC_German-to-English', 'XNLI_Zero-Shot_English-to-Spanish'}\n",
      "====================\n",
      "175f74a09241b6cb5101a2a09978095720db7d5f\n",
      "{'Urban100_-_4x_upscaling', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'DSRN', 'PSNR'}\n",
      "{'Urban100_-_4x_upscaling', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'DSRN', 'PSNR'}\n",
      "====================\n",
      "1778e32c18bd611169e64c1805a51abff341ca53\n",
      "{'Accuracy', 'Ensemble', 'DIIN', 'Paraphrase_Identification', 'Quora_Question_Pairs', '448D_Densely_Interactive_Inference_Network', 'SNLI', 'Natural_Language_Inference'}\n",
      "{'Accuracy', 'Paraphrase_Identification', 'DIIN', 'Quora_Question_Pairs', 'SNLI', 'Natural_Language_Inference'}\n",
      "====================\n",
      "178275dbdcfa267e41a9d5efe386ee5874c6d23f\n",
      "{'WikiText-2', 'AWD-LSTM_3-layer_with_Fraternal_dropout', 'Penn_Treebank__Word_Level_', 'Validation_perplexity', 'Test_perplexity', 'Language_Modelling'}\n",
      "{'Language_Modelling', 'Penn_Treebank__Word_Level_', 'WikiText-2'}\n",
      "====================\n",
      "178631e0f0e624b1607c7a7a2507ed30d4e83a42\n",
      "{'Bi-LSTM', 'Speech_Recognition', 'TIMIT', 'Percentage_error'}\n",
      "{'Percentage_error', 'Speech_Recognition', 'TIMIT'}\n",
      "====================\n",
      "18168aea48a22f6fe2fe407c0ff70083cba225a7\n",
      "{'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'RED30', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "{'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "====================\n",
      "193089d56758ab88391d846edd08d359b1f9a863\n",
      "{'Rank-1', 'DLCE', 'MAP', 'Market-1501', 'Person_Re-Identification'}\n",
      "{'Person_Re-Identification', 'Market-1501', 'Rank-1', 'MAP'}\n",
      "====================\n",
      "193b518bc3025804c6d587c74cbc154d91478417\n",
      "{'Synthetic-to-Real_Translation', 'Single-level_Adaptation', 'mIoU'}\n",
      "{'mIoU'}\n",
      "====================\n",
      "1d0dcb458aa4d30b51f7c74b159be687f39120a0\n",
      "{'MAP', 'Market-1501', 'Person_Re-Identification', 'Rank-1'}\n",
      "{'Person_Re-Identification', 'Rank-1', 'MAP'}\n",
      "====================\n",
      "1f08598381af9146d0fd9a61b30d0e51a7331689\n",
      "{'Ape-X', 'Atari_Games', 'Medium_Human-Normalized_Score'}\n",
      "{'Ape-X', 'Atari_Games', 'Medium_Human-Normalized_Score'}\n",
      "====================\n",
      "2138a7127429d67746ec78de46d6820fee0e548e\n",
      "{'Graph2Seq-PGE', 'SQL-to-Text', 'WikiSQL', 'BLEU-4'}\n",
      "{'BLEU-4'}\n",
      "====================\n",
      "21a1654b856cf0c64e60e58258669b374cb05539\n",
      "{'YOLO', 'PASCAL_VOC_2007', 'MAP', 'Real-Time_Object_Detection', 'Object_Detection', 'FPS'}\n",
      "{'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "232b43584b2236669c0a53702ad89ab10c3886ea\n",
      "{'Score', 'Atari_Games', 'Atari_2600_Assault', 'Atari_2600_Breakout', 'Atari_2600_James_Bond', 'Atari_2600_Q_Bert', 'Atari_2600_Space_Invaders', 'IQN', 'Atari_2600_Asterix'}\n",
      "{'Score', 'Atari_2600_James_Bond', 'Atari_Games'}\n",
      "====================\n",
      "23d2d3a6ffebfecaa8930307fdcf451c147757c8\n",
      "{'SeqGAN', 'BLEU-2', 'Text_Generation', 'Chinese_Poems', 'BLEU-4', 'BLEU-3'}\n",
      "{'SeqGAN'}\n",
      "====================\n",
      "24730424236724d3f798dec02901e7a1f1c4710e\n",
      "{'JMPF', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR', 'JMPF_'}\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "====================\n",
      "249b3b7421d3cdb932eecfe4b67203e0e46806b2\n",
      "{'SST-2_Binary_classification', 'Bi-CAS-LSTM', 'Accuracy', 'Paraphrase_Identification', 'Quora_Question_Pairs', 'SST-5_Fine-grained_classification', 'SNLI', 'Sentiment_Analysis', 'Natural_Language_Inference'}\n",
      "{'SST-2_Binary_classification', 'Accuracy', 'Paraphrase_Identification', 'Quora_Question_Pairs', 'SST-5_Fine-grained_classification', 'SNLI', 'Sentiment_Analysis', 'Natural_Language_Inference'}\n",
      "====================\n",
      "25a784f7f8c94c42821ee078587fc38dffcd00a4\n",
      "{'AP', 'Annotated_Faces_in_the_Wild', 'WIDER_Face__Hard_', 'Face_Detection', 'FDDB', 'PASCAL_Face', 'Anchor-based'}\n",
      "{'AP', 'Annotated_Faces_in_the_Wild', 'WIDER_Face__Hard_', 'Face_Detection', 'FDDB', 'PASCAL_Face'}\n",
      "====================\n",
      "25f5df29342a04936ba0d308b4d1b8245a7e8f5c\n",
      "{'Convolutional_Pose_Machines', 'FLIC_Wrists', 'Pose_Estimation', 'PCK_0_2', 'PCK', 'PCKh-0_5', 'FLIC_Elbows', 'Leeds_Sports_Poses', 'MPII_Human_Pose'}\n",
      "{'MPII_Human_Pose', 'FLIC_Wrists', 'PCK_0_2', 'PCK', 'PCKh-0_5', 'Leeds_Sports_Poses', 'FLIC_Elbows'}\n",
      "====================\n",
      "269730dbbabed8b8b5ba720e44a4c31b1f51e8f1\n",
      "{'bAbi', 'QRN', 'Mean_Error_Rate', 'Question_Answering'}\n",
      "{'bAbi', 'Mean_Error_Rate', 'Question_Answering'}\n",
      "====================\n",
      "270e65acc071b9e4e2a632720130c0e10cb6fa08\n",
      "{'Natural_Language_Inference', '__Test_Accuracy', 'SNLI', '300D_NTI-SLSTM-LSTM_encoders'}\n",
      "{'Natural_Language_Inference', 'SNLI'}\n",
      "====================\n",
      "2777cd26b2c257843273fe41ad4c5b8cdf1b1b75\n",
      "{'NAN', 'PASCAL-Person-Part', 'Multi-Human_Parsing', 'MHP_v1_0', 'MHP_v2_0'}\n",
      "{'NAN', 'PASCAL-Person-Part', 'Multi-Human_Parsing', 'MHP_v1_0', 'MHP_v2_0'}\n",
      "====================\n",
      "27a99c21a1324f087b2f144adc119f04137dfd87\n",
      "{'Percentage_error', 'MNIST', 'Deep_Fried_Convnets'}\n",
      "{'Percentage_error', 'MNIST'}\n",
      "====================\n",
      "27aa0f3ec934925265f93fac7ff1cd1d70ceb618\n",
      "{'Average', 'Multi-task_tri-training', 'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "{'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "====================\n",
      "2a86bcdfb1d817ddb76ba202319f8267a36c0f62\n",
      "{'ImageNet', 'Weakly_Supervised_Object_Detection', 'PCL-OB-G-Ens', 'PASCAL_VOC_2012', 'FRCNN', 'PASCAL_VOC_2007', 'MAP', 'PCL-OB-G-Ens___FRCNN'}\n",
      "{'MAP', 'PASCAL_VOC_2012', 'Weakly_Supervised_Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "2f04ba0f74df046b0080ca78e56898bd4847898b\n",
      "{'AP', 'ACF-WIDER', 'Face_Detection'}\n",
      "{'ACF-WIDER', 'Face_Detection'}\n",
      "====================\n",
      "2f56b1ac5b9faac9527b6814778925e9242cf5fd\n",
      "{'OHEM', 'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'OHEM', 'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "2f97ee95cad6a1f13596b108072b846c6f747d4e\n",
      "{'RNNLM_language_model_trained_on_Switchboard', 'VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB', 'Speech_Recognition', 'CH__N-gram', 'Percentage_error', 'VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram___RNNLM_language_model_trained_on_Switchboard_Fisher_Gigaword_Broadcast', 'Switchboard___Hub500', 'RNNLM'}\n",
      "{'Percentage_error', 'Switchboard___Hub500', 'Speech_Recognition'}\n",
      "====================\n",
      "322a7dad274f440a92548faa8f2b2be666b2d01f\n",
      "{'mIoU', 'PSPNet', 'PASCAL_VOC_2012', 'ADE20K', 'Cityscapes', 'Test_Score', 'Mean_IoU', 'Semantic_Segmentation'}\n",
      "{'PASCAL_VOC_2012', 'ADE20K', 'Cityscapes', 'Mean_IoU', 'mIoU'}\n",
      "====================\n",
      "325af39d281d5903a269c01fab8f53d7400a4c49\n",
      "{'AP', 'Articulated_Tracking', 'MPII_Multi-Person', 'Multi-Person_Pose_Estimation'}\n",
      "{'MPII_Multi-Person', 'AP', 'Multi-Person_Pose_Estimation'}\n",
      "====================\n",
      "33261d252218007147a71e40f8367ed152fa2fe0\n",
      "{'Subgraph_embeddings', 'Question_Answering', 'WebQuestions', 'F1'}\n",
      "{'Question_Answering'}\n",
      "====================\n",
      "3448e6a5039417dc1ae890efeca3bef5390ace7c\n",
      "{'Criteo', 'Dianping', 'AUC', 'Click-Through_Rate_Prediction', 'Bing_News', 'Log_Loss', 'xDeepFM'}\n",
      "{'Bing_News', 'xDeepFM'}\n",
      "====================\n",
      "35734e8724559fb0d494e5cba6a28ad7a3d5dd4d\n",
      "{'Percentage_error', 'Explaining_and_Harnessing_Adversarial_Examples', 'Image_Classification', 'MNIST'}\n",
      "{'Percentage_error', 'MNIST'}\n",
      "====================\n",
      "364c1a3df58d87cb40ab33fdf3831cf2862f3570\n",
      "{'aNMM', 'MAP', 'MRR', 'TrecQA', 'Question_Answering'}\n",
      "{'MAP', 'MRR', 'Question_Answering', 'TrecQA'}\n",
      "====================\n",
      "3842ee1e0fdfeff936b5c49973ff21adfaaf3929\n",
      "{'Unsupervised_Image-To-Image_Translation', 'SVNH-to-MNIST', 'ADDA', 'Classification_Accuracy'}\n",
      "{'Classification_Accuracy', 'SVNH-to-MNIST'}\n",
      "====================\n",
      "38cc89399dd6f5aaab1654f27ab3c9eeade12a36\n",
      "{'Average_3D_Error', '3D_Human_Pose_Estimation', 'Sequence-to-sequence_network_', 'Human3_6M'}\n",
      "{'Average_3D_Error', 'Human3_6M'}\n",
      "====================\n",
      "38e2f851b705faa0d0a698ed9885bd6834440073\n",
      "{'PLATIPUS', 'Few-Shot_Image_Classification', 'Mini-ImageNet_-_1-Shot_Learning', 'Accuracy'}\n",
      "{'Mini-ImageNet_-_1-Shot_Learning', 'Accuracy'}\n",
      "====================\n",
      "3aa21de1a7c97e0458e10ed5730ce160bb436caa\n",
      "{'Avg_F1', '3D_Object_Reconstruction', 'Data3D_R2N2', 'Pixel2Mesh'}\n",
      "{'Avg_F1'}\n",
      "====================\n",
      "3acc07f7f8951617276cf99483ed02aeb0a6eeac\n",
      "{'GTAV-to-Cityscapes_Labels', 'CDA', 'mIoU'}\n",
      "{'GTAV-to-Cityscapes_Labels', 'mIoU'}\n",
      "====================\n",
      "3ca3993b1f3536b15112f759067f62e999c5d38f\n",
      "{'BB8', 'LineMOD', 'Accuracy'}\n",
      "{'LineMOD'}\n",
      "====================\n",
      "3cf31ecb2724b5088783d7c96a5fc0d5604cbf41\n",
      "{'UAS', 'POS', 'BIST_graph-based_parser', 'BIST_transition-based_parser', 'Penn_Treebank', 'Dependency_Parsing', 'LAS'}\n",
      "{'UAS', 'Dependency_Parsing'}\n",
      "====================\n",
      "3daa086acd367dc971a2dc1382caba2031294233\n",
      "{'Holistic_instance-level', 'AP_0_5', 'Multi-Human_Parsing', 'PASCAL-Person-Part'}\n",
      "{'Holistic_instance-level', 'AP_0_5', 'PASCAL-Person-Part'}\n",
      "====================\n",
      "408e8eecc14c5cc60bbdfc486ba7a7fc97031788\n",
      "{'CIFAR-10', 'Image_Classification', 'Discriminative_Unsupervised_Feature_Learning_with_Convolutional_Neural_Networks', 'STL-10'}\n",
      "{'CIFAR-10', 'Image_Classification', 'STL-10'}\n",
      "====================\n",
      "4365eb43a635bc6431dfaf3af1f7bf7bf55522cc\n",
      "{'MAP', 'CoupleNet', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'MAP', 'CoupleNet', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "436b07bebaa1d1f05ef85415e10374048d25334d\n",
      "{'PPL', 'Machine_Translation', 'Number_of_params', 'MoE', 'WMT2014_English-French', 'WMT2014_English-German', 'One_Billion_Word', 'BLEU_score', 'Language_Modelling'}\n",
      "{'PPL', 'Machine_Translation', 'WMT2014_English-French', 'MoE', 'WMT2014_English-German', 'One_Billion_Word', 'BLEU_score', 'Language_Modelling'}\n",
      "====================\n",
      "44078d0daed8b13114cffb15b368acc467f96351\n",
      "{'IJB-A', 'Triplet_probabilistic_embedding', 'TAR___FAR_0_01', 'Face_Verification'}\n",
      "{'IJB-A', 'TAR___FAR_0_01', 'Face_Verification'}\n",
      "====================\n",
      "45429c281e30f9e87ebcd1ae42e0656d2ead24d1\n",
      "{'ADE20K_Labels-to-Photos', 'Cityscapes_Labels-to-Photo', 'Accuracy', 'Image-to-Image_Translation', 'pix2pixHD', 'ADE20K-Outdoor_Labels-to-Photos', 'Class_IOU'}\n",
      "{'ADE20K_Labels-to-Photos', 'pix2pixHD', 'Cityscapes_Labels-to-Photo', 'Class_IOU'}\n",
      "====================\n",
      "455da02e5048dffb51fb6ab5eb8aeca5926c9d9a\n",
      "{'SPP', 'PASCAL_VOC_2007', 'MAP', 'Object_Detection', 'Overfeat-7'}\n",
      "{'MAP', 'SPP', 'PASCAL_VOC_2007'}\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for d in documents :\n",
    "    print(d)\n",
    "    print(set(list(documents[d]['coref'].keys())))\n",
    "    print(set([x for k,v in documents[d]['intersection_scores'].items() for x, _ in v.items()]))\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_clustering = []\n",
    "for d in documents :\n",
    "    n_clusters_clustering.append(len(documents[d]['predicted_clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02567fd428a675ca91a0c6786f47f3e35881bcbd\n",
      "Age_Estimation 48 True\n",
      "ChaLearn_2015 21 True\n",
      "DLDL 84 True\n",
      "MAE 20 True\n",
      "MORPH_Album2 21 True\n",
      "VGG-Face 4 False\n",
      "====================\n",
      "02b3d1d162080d9aefd3fc30a0bcc9a843073b5d\n",
      "CNN_Input 2 False\n",
      "LSTM-8192-1024 38 False\n",
      "LSTM-8192-1024___CNN_Input 35 False\n",
      "Language_Modelling 37 True\n",
      "One_Billion_Word 6 False\n",
      "====================\n",
      "0398552184f80db111e9c28bf533b395f233ac00\n",
      "PASCAL_VOC_2007 2 True\n",
      "Self-paced_curriculum_learning 29 True\n",
      "Weakly_Supervised_Object_Detection 41 True\n",
      "====================\n",
      "05d2700846c0323f79c1344aca5333994c7c03a5\n",
      "CH__N-gram 6 False\n",
      "LSTM_acoustic_model_trained_on_SWB 18 False\n",
      "NNLM_language_model 6 False\n",
      "Percentage_error 4 True\n",
      "RNN 20 False\n",
      "RNN___VGG___LSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram____model_M____NNLM_language_model 1 False\n",
      "Speech_Recognition 6 True\n",
      "Switchboard___Hub500 12 True\n",
      "VGG 4 False\n",
      "_model_M_ 5 False\n",
      "swb_hub_500_WER_fullSWBCH 6 True\n",
      "====================\n",
      "0626908dd710b91aece1a81f4ca0635f23fc47f3\n",
      "ImageNet 8 True\n",
      "Image_Classification 2 False\n",
      "Inception_V3 23 True\n",
      "Top_1_Accuracy 14 True\n",
      "Top_5_Accuracy 15 True\n",
      "====================\n",
      "0678a8abea82793993cd89383319da75f6dc4be3\n",
      "COCO 11 True\n",
      "MAP 5 True\n",
      "ProNet 28 True\n",
      "Weakly_Supervised_Object_Detection 12 False\n",
      "====================\n",
      "081531984770a74e87dbd68907061b4b0f3631bf\n",
      "MOVIE 3 False\n",
      "PSNR 5 True\n",
      "SSIM 2 True\n",
      "VESPCN 10 True\n",
      "Vid4_-_4x_upscaling 2 True\n",
      "Video_Super-Resolution 41 True\n",
      "bicubic 4 False\n",
      "====================\n",
      "0834e74304b547c9354b6d7da6fa78ef47a48fa8\n",
      "LINE 123 True\n",
      "Macro-F1 1 False\n",
      "Node_Classification 13 True\n",
      "Wikipedia 8 False\n",
      "====================\n",
      "0a3381f0432c5cfe491c718349d7a44e5814592c\n",
      "Bi-LSTM 2 False\n",
      "CoNLL-2014_A1 7 True\n",
      "CoNLL-2014_A2 1 False\n",
      "FCE 16 True\n",
      "Grammatical_Error_Detection 35 True\n",
      "====================\n",
      "0a6c36de8726b6feaab586046ddc1d1a008f44f9\n",
      "Caltech 43 True\n",
      "Checkerboards_ 9 True\n",
      "Pedestrian_Detection 11 True\n",
      "Reasonable_Miss_Rate 5 True\n",
      "====================\n",
      "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e\n",
      "Accuracy 13 False\n",
      "CCGBank 1 False\n",
      "CCG_Supertagging 6 False\n",
      "CVT 69 True\n",
      "CoNLL_2003__English_ 1 False\n",
      "Dependency_Parsing 8 True\n",
      "Multi-Task 28 True\n",
      "Named_Entity_Recognition__NER_ 7 True\n",
      "Ontonotes_v5__English_ 1 False\n",
      "POS 2 False\n",
      "Penn_Treebank 4 True\n",
      "====================\n",
      "0dc9eb7d17f2def56ad930945f2521653f04c3fa\n",
      "Language_Modelling 7 True\n",
      "Number_of_params 1 False\n",
      "One_Billion_Word 4 False\n",
      "PPL 13 True\n",
      "Sparse_Non-Negative 37 True\n",
      "====================\n",
      "107010b7f2abe3c0c9df62bcef35eb77f6fc76df\n",
      "DANN 69 True\n",
      "Multi-Domain_Sentiment_Dataset 15 True\n",
      "Sentiment_Analysis 5 True\n",
      "====================\n",
      "1130d8fdd931225c2d7563c3808367726cfa1c3a\n",
      "MNIST 31 True\n",
      "PixelGAN_Autoencoders 19 True\n",
      "Unsupervised_MNIST 4 False\n",
      "Unsupervised_image_classification 2 True\n",
      "====================\n",
      "11356cd6bb0f2776a88cd584ff108470414c6594\n",
      "SSCN 2 False\n",
      "====================\n",
      "11da0c54ba904a1cb31a09d10da55f73e8825c61\n",
      "300D_Tree-based_CNN_encoders 25 True\n",
      "Natural_Language_Inference 9 True\n",
      "SNLI 3 True\n",
      "__Test_Accuracy 5 False\n",
      "====================\n",
      "1235dd37312cb20aced0e97d953f6379d8a0c7d4\n",
      "Accuracy 7 False\n",
      "BiMPM 13 True\n",
      "Natural_Language_Inference 3 True\n",
      "V-BiMPM 12 True\n",
      "V-SNLI 28 True\n",
      "====================\n",
      "14318685b5959b51d0f1e3db34643eb2855dc6d9\n",
      "ImageNet 3 False\n",
      "Image_Classification 12 False\n",
      "Inception_V1 21 False\n",
      "MAP 3 True\n",
      "Object_Detection 18 True\n",
      "Top_1_Accuracy 2 True\n",
      "Top_5_Accuracy 3 True\n",
      "====================\n",
      "16051bbe3a7f7c77a952ebf76722ea655e8906ca\n",
      "BSD100_-_4x_upscaling 2 True\n",
      "FAFR_ 1 False\n",
      "FARF_ 25 True\n",
      "Image_Super-Resolution 42 True\n",
      "PSNR 6 True\n",
      "Set14_-_4x_upscaling 2 True\n",
      "Set5_-_4x_upscaling 1 False\n",
      "====================\n",
      "160563abbd75265b19afc8b4169bab9e1eb33d97\n",
      "Accuracy 5 False\n",
      "BUCC_French-to-English 35 True\n",
      "BUCC_German-to-English 9 True\n",
      "BiLSTM 10 False\n",
      "Cross-Lingual_Bitext_Mining 5 False\n",
      "Cross-Lingual_Document_Classification 6 False\n",
      "Cross-Lingual_Natural_Language_Inference 4 True\n",
      "MLDoc_Zero-Shot_English-to-French 10 True\n",
      "MLDoc_Zero-Shot_English-to-German 10 True\n",
      "MLDoc_Zero-Shot_English-to-Spanish 16 True\n",
      "Massively_Multilingual_Sentence_Embeddings 28 False\n",
      "XNLI_Zero-Shot_English-to-French 18 True\n",
      "XNLI_Zero-Shot_English-to-German 17 True\n",
      "XNLI_Zero-Shot_English-to-Spanish 17 True\n",
      "====================\n",
      "175f74a09241b6cb5101a2a09978095720db7d5f\n",
      "BSD100_-_4x_upscaling 1 True\n",
      "DSRN 31 True\n",
      "Image_Super-Resolution 42 True\n",
      "PSNR 3 True\n",
      "SSIM 2 False\n",
      "Set14_-_4x_upscaling 2 True\n",
      "Set5_-_4x_upscaling 1 True\n",
      "Urban100_-_4x_upscaling 1 True\n",
      "====================\n",
      "1778e32c18bd611169e64c1805a51abff341ca53\n",
      "448D_Densely_Interactive_Inference_Network 4 True\n",
      "Accuracy 5 False\n",
      "DIIN 20 True\n",
      "Ensemble 1 False\n",
      "Natural_Language_Inference 23 True\n",
      "Paraphrase_Identification 3 True\n",
      "Quora_Question_Pairs 5 True\n",
      "SNLI 13 True\n",
      "====================\n",
      "178275dbdcfa267e41a9d5efe386ee5874c6d23f\n",
      "AWD-LSTM_3-layer_with_Fraternal_dropout 54 True\n",
      "Language_Modelling 5 True\n",
      "Penn_Treebank__Word_Level_ 4 True\n",
      "Test_perplexity 2 False\n",
      "Validation_perplexity 5 False\n",
      "WikiText-2 2 True\n",
      "====================\n",
      "178631e0f0e624b1607c7a7a2507ed30d4e83a42\n",
      "Bi-LSTM 3 False\n",
      "Percentage_error 4 True\n",
      "Speech_Recognition 14 True\n",
      "TIMIT 3 True\n",
      "====================\n",
      "18168aea48a22f6fe2fe407c0ff70083cba225a7\n",
      "BSD100_-_4x_upscaling 4 True\n",
      "Image_Super-Resolution 20 True\n",
      "PSNR 8 True\n",
      "RED30 1 False\n",
      "SSIM 5 True\n",
      "Set5_-_4x_upscaling 4 True\n",
      "====================\n",
      "193089d56758ab88391d846edd08d359b1f9a863\n",
      "DLCE 1 False\n",
      "MAP 16 True\n",
      "Market-1501 18 True\n",
      "Person_Re-Identification 33 True\n",
      "Rank-1 14 True\n",
      "====================\n",
      "193b518bc3025804c6d587c74cbc154d91478417\n",
      "Single-level_Adaptation 14 False\n",
      "Synthetic-to-Real_Translation 4 False\n",
      "mIoU 4 True\n",
      "====================\n",
      "1d0dcb458aa4d30b51f7c74b159be687f39120a0\n",
      "MAP 5 True\n",
      "Market-1501 11 True\n",
      "Person_Re-Identification 35 True\n",
      "Rank-1 7 True\n",
      "====================\n",
      "1f08598381af9146d0fd9a61b30d0e51a7331689\n",
      "Ape-X 39 True\n",
      "Atari_Games 10 True\n",
      "Medium_Human-Normalized_Score 2 True\n",
      "====================\n",
      "2138a7127429d67746ec78de46d6820fee0e548e\n",
      "BLEU-4 1 True\n",
      "Graph2Seq-PGE 1 True\n",
      "SQL-to-Text 1 False\n",
      "WikiSQL 3 False\n",
      "====================\n",
      "21a1654b856cf0c64e60e58258669b374cb05539\n",
      "FPS 4 True\n",
      "MAP 15 True\n",
      "Object_Detection 38 True\n",
      "PASCAL_VOC_2007 15 True\n",
      "Real-Time_Object_Detection 3 True\n",
      "YOLO 75 True\n",
      "====================\n",
      "232b43584b2236669c0a53702ad89ab10c3886ea\n",
      "Atari_2600_Assault 2 False\n",
      "Atari_2600_Asterix 2 False\n",
      "Atari_2600_Breakout 1 False\n",
      "Atari_2600_James_Bond 6 True\n",
      "Atari_2600_Q_Bert 2 False\n",
      "Atari_2600_Space_Invaders 2 False\n",
      "Atari_Games 14 True\n",
      "IQN 42 True\n",
      "Score 5 True\n",
      "====================\n",
      "23d2d3a6ffebfecaa8930307fdcf451c147757c8\n",
      "BLEU-2 1 True\n",
      "BLEU-3 1 True\n",
      "BLEU-4 1 True\n",
      "Chinese_Poems 6 True\n",
      "SeqGAN 44 True\n",
      "Text_Generation 28 True\n",
      "====================\n",
      "24730424236724d3f798dec02901e7a1f1c4710e\n",
      "BSD100_-_4x_upscaling 3 True\n",
      "Image_Super-Resolution 26 True\n",
      "JMPF 60 True\n",
      "JMPF_ 5 True\n",
      "PSNR 5 True\n",
      "Set14_-_4x_upscaling 1 False\n",
      "Set5_-_4x_upscaling 3 True\n",
      "====================\n",
      "249b3b7421d3cdb932eecfe4b67203e0e46806b2\n",
      "Accuracy 5 True\n",
      "Bi-CAS-LSTM 1 False\n",
      "Natural_Language_Inference 9 True\n",
      "Paraphrase_Identification 7 True\n",
      "Quora_Question_Pairs 5 True\n",
      "SNLI 10 True\n",
      "SST-2_Binary_classification 9 True\n",
      "SST-5_Fine-grained_classification 5 True\n",
      "Sentiment_Analysis 5 True\n",
      "====================\n",
      "25a784f7f8c94c42821ee078587fc38dffcd00a4\n",
      "AP 10 True\n",
      "Anchor-based 5 False\n",
      "Annotated_Faces_in_the_Wild 3 True\n",
      "FDDB 7 True\n",
      "Face_Detection 13 True\n",
      "PASCAL_Face 9 True\n",
      "WIDER_Face__Hard_ 28 True\n",
      "====================\n",
      "25f5df29342a04936ba0d308b4d1b8245a7e8f5c\n",
      "Convolutional_Pose_Machines 30 True\n",
      "FLIC_Elbows 8 True\n",
      "FLIC_Wrists 8 True\n",
      "Leeds_Sports_Poses 16 True\n",
      "MPII_Human_Pose 11 True\n",
      "PCK 7 True\n",
      "PCK_0_2 2 True\n",
      "PCKh-0_5 2 True\n",
      "Pose_Estimation 6 True\n",
      "====================\n",
      "269730dbbabed8b8b5ba720e44a4c31b1f51e8f1\n",
      "Mean_Error_Rate 2 True\n",
      "QRN 82 True\n",
      "Question_Answering 27 True\n",
      "bAbi 11 True\n",
      "====================\n",
      "270e65acc071b9e4e2a632720130c0e10cb6fa08\n",
      "300D_NTI-SLSTM-LSTM_encoders 5 True\n",
      "Natural_Language_Inference 7 True\n",
      "SNLI 6 True\n",
      "__Test_Accuracy 2 False\n",
      "====================\n",
      "2777cd26b2c257843273fe41ad4c5b8cdf1b1b75\n",
      "MHP_v1_0 7 True\n",
      "MHP_v2_0 19 True\n",
      "Multi-Human_Parsing 36 True\n",
      "NAN 66 True\n",
      "PASCAL-Person-Part 8 True\n",
      "====================\n",
      "27a99c21a1324f087b2f144adc119f04137dfd87\n",
      "Deep_Fried_Convnets 19 True\n",
      "MNIST 9 True\n",
      "Percentage_error 5 True\n",
      "====================\n",
      "27aa0f3ec934925265f93fac7ff1cd1d70ceb618\n",
      "Average 2 False\n",
      "Multi-Domain_Sentiment_Dataset 1 True\n",
      "Multi-task_tri-training 5 True\n",
      "Sentiment_Analysis 12 True\n",
      "====================\n",
      "2a86bcdfb1d817ddb76ba202319f8267a36c0f62\n",
      "FRCNN 8 True\n",
      "ImageNet 11 True\n",
      "MAP 15 True\n",
      "PASCAL_VOC_2007 12 True\n",
      "PASCAL_VOC_2012 13 True\n",
      "PCL-OB-G-Ens 2 True\n",
      "PCL-OB-G-Ens___FRCNN 1 True\n",
      "Weakly_Supervised_Object_Detection 33 True\n",
      "====================\n",
      "2f04ba0f74df046b0080ca78e56898bd4847898b\n",
      "ACF-WIDER 12 True\n",
      "AP 6 False\n",
      "Face_Detection 1 True\n",
      "====================\n",
      "2f56b1ac5b9faac9527b6814778925e9242cf5fd\n",
      "MAP 22 True\n",
      "OHEM 47 True\n",
      "Object_Detection 12 True\n",
      "PASCAL_VOC_2007 21 True\n",
      "====================\n",
      "2f97ee95cad6a1f13596b108072b846c6f747d4e\n",
      "CH__N-gram 3 False\n",
      "Percentage_error 8 True\n",
      "RNNLM 23 False\n",
      "RNNLM_language_model_trained_on_Switchboard 10 False\n",
      "Speech_Recognition 6 True\n",
      "Switchboard___Hub500 12 True\n",
      "VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB 21 True\n",
      "VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram___RNNLM_language_model_trained_on_Switchboard_Fisher_Gigaword_Broadcast 11 False\n",
      "====================\n",
      "322a7dad274f440a92548faa8f2b2be666b2d01f\n",
      "ADE20K 9 True\n",
      "Cityscapes 7 True\n",
      "Mean_IoU 4 True\n",
      "PASCAL_VOC_2012 12 True\n",
      "PSPNet 37 True\n",
      "Semantic_Segmentation 14 True\n",
      "Test_Score 4 False\n",
      "mIoU 2 True\n",
      "====================\n",
      "325af39d281d5903a269c01fab8f53d7400a4c49\n",
      "AP 30 True\n",
      "Articulated_Tracking 6 True\n",
      "MPII_Multi-Person 16 True\n",
      "Multi-Person_Pose_Estimation 9 True\n",
      "====================\n",
      "33261d252218007147a71e40f8367ed152fa2fe0\n",
      "F1 4 True\n",
      "Question_Answering 8 True\n",
      "Subgraph_embeddings 6 False\n",
      "WebQuestions 7 True\n",
      "====================\n",
      "3448e6a5039417dc1ae890efeca3bef5390ace7c\n",
      "AUC 4 False\n",
      "Bing_News 5 True\n",
      "Click-Through_Rate_Prediction 2 False\n",
      "Criteo 3 True\n",
      "Dianping 4 True\n",
      "Log_Loss 5 True\n",
      "xDeepFM 37 True\n",
      "====================\n",
      "35734e8724559fb0d494e5cba6a28ad7a3d5dd4d\n",
      "Explaining_and_Harnessing_Adversarial_Examples 21 False\n",
      "Image_Classification 5 False\n",
      "MNIST 12 True\n",
      "Percentage_error 37 True\n",
      "====================\n",
      "364c1a3df58d87cb40ab33fdf3831cf2862f3570\n",
      "MAP 10 True\n",
      "MRR 11 True\n",
      "Question_Answering 16 True\n",
      "TrecQA 3 True\n",
      "aNMM 42 True\n",
      "====================\n",
      "3842ee1e0fdfeff936b5c49973ff21adfaaf3929\n",
      "ADDA 28 True\n",
      "Classification_Accuracy 7 False\n",
      "SVNH-to-MNIST 2 True\n",
      "Unsupervised_Image-To-Image_Translation 1 False\n",
      "====================\n",
      "38cc89399dd6f5aaab1654f27ab3c9eeade12a36\n",
      "3D_Human_Pose_Estimation 9 True\n",
      "Average_3D_Error 2 True\n",
      "Human3_6M 21 True\n",
      "Sequence-to-sequence_network_ 8 False\n",
      "====================\n",
      "38e2f851b705faa0d0a698ed9885bd6834440073\n",
      "Accuracy 5 False\n",
      "Few-Shot_Image_Classification 4 True\n",
      "Mini-ImageNet_-_1-Shot_Learning 4 True\n",
      "PLATIPUS 13 True\n",
      "====================\n",
      "3aa21de1a7c97e0458e10ed5730ce160bb436caa\n",
      "3D_Object_Reconstruction 3 True\n",
      "Avg_F1 5 True\n",
      "Data3D_R2N2 1 False\n",
      "Pixel2Mesh 1 True\n",
      "====================\n",
      "3acc07f7f8951617276cf99483ed02aeb0a6eeac\n",
      "CDA 11 True\n",
      "GTAV-to-Cityscapes_Labels 1 False\n",
      "mIoU 1 False\n",
      "====================\n",
      "3ca3993b1f3536b15112f759067f62e999c5d38f\n",
      "Accuracy 5 False\n",
      "BB8 3 False\n",
      "LineMOD 16 True\n",
      "====================\n",
      "3cf31ecb2724b5088783d7c96a5fc0d5604cbf41\n",
      "BIST_graph-based_parser 20 False\n",
      "BIST_transition-based_parser 46 True\n",
      "Dependency_Parsing 13 True\n",
      "LAS 2 False\n",
      "POS 12 False\n",
      "Penn_Treebank 4 True\n",
      "UAS 10 True\n",
      "====================\n",
      "3daa086acd367dc971a2dc1382caba2031294233\n",
      "AP_0_5 11 True\n",
      "Holistic_instance-level 33 True\n",
      "Multi-Human_Parsing 4 True\n",
      "PASCAL-Person-Part 12 True\n",
      "====================\n",
      "408e8eecc14c5cc60bbdfc486ba7a7fc97031788\n",
      "CIFAR-10 13 True\n",
      "Discriminative_Unsupervised_Feature_Learning_with_Convolutional_Neural_Networks 12 False\n",
      "Image_Classification 18 True\n",
      "STL-10 14 True\n",
      "====================\n",
      "4365eb43a635bc6431dfaf3af1f7bf7bf55522cc\n",
      "CoupleNet 19 True\n",
      "MAP 12 True\n",
      "Object_Detection 27 True\n",
      "PASCAL_VOC_2007 15 True\n",
      "====================\n",
      "436b07bebaa1d1f05ef85415e10374048d25334d\n",
      "BLEU_score 6 True\n",
      "Language_Modelling 8 True\n",
      "Machine_Translation 9 True\n",
      "MoE 126 True\n",
      "Number_of_params 1 False\n",
      "One_Billion_Word 5 True\n",
      "PPL 5 True\n",
      "WMT2014_English-French 3 True\n",
      "WMT2014_English-German 2 True\n",
      "====================\n",
      "44078d0daed8b13114cffb15b368acc467f96351\n",
      "Face_Verification 22 True\n",
      "IJB-A 39 True\n",
      "TAR___FAR_0_01 3 True\n",
      "Triplet_probabilistic_embedding 18 True\n",
      "====================\n",
      "45429c281e30f9e87ebcd1ae42e0656d2ead24d1\n",
      "ADE20K-Outdoor_Labels-to-Photos 1 False\n",
      "ADE20K_Labels-to-Photos 3 True\n",
      "Accuracy 2 False\n",
      "Cityscapes_Labels-to-Photo 8 True\n",
      "Class_IOU 2 True\n",
      "Image-to-Image_Translation 6 True\n",
      "pix2pixHD 3 True\n",
      "====================\n",
      "455da02e5048dffb51fb6ab5eb8aeca5926c9d9a\n",
      "MAP 13 True\n",
      "Object_Detection 18 True\n",
      "Overfeat-7 6 True\n",
      "PASCAL_VOC_2007 14 True\n",
      "SPP 91 True\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "data_ner = []\n",
    "for d in documents :\n",
    "    print(d)\n",
    "    linked = set([x for k in documents[d]['linked_clusters'] for x, _ in documents[d]['intersection_scores'][k].items()])\n",
    "    for k, v in documents[d]['coref'].items() :\n",
    "        print(k, len(v), k in linked)\n",
    "        data.append({'len' : len(v), 'linked' : k in linked})\n",
    "        data_ner.append({'linked' : k in linked, 'in_train' : re.sub(r'\\W+', '', k) in ner})\n",
    "#     print(set(list(documents[d]['coref'].keys())))\n",
    "#     print(set([(x, len(documents[d]['coref'][x])) for k,v in documents[d]['intersection_scores'].items() for x, _ in v.items()]))\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = documents[list(documents.keys())[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'NLP', 'NLP tasks', 'NLP', 'NLP problems']\n",
      "False\n",
      "['character level CNNs', 'character embedding CNNs', 'character CNNs']\n",
      "False\n",
      "['low perplexity LMs', 'perplexity']\n",
      "False\n",
      "['single layer LSTM', 'single - layer LSTM of 1024 units']\n",
      "False\n",
      "['language modeling', 'Language Modeling', 'language modeling', 'neural language modeling', 'language modeling', 'language modeling', 'statistical language modeling', 'language modeling', 'Language Modeling']\n",
      "True\n",
      "['question answering', 'inference', 'inference', 'inference']\n",
      "False\n",
      "['One Billion Word Benchmark', 'One Billion Word Benchmark data set', 'One Billion Word Benchmark', '1B Word Benchmark data set', '1B Word Benchmark data set']\n",
      "False\n",
      "['CNN character embeddings', 'character - level embeddings', 'character - level embeddings']\n",
      "False\n",
      "['word error rate', 'IS', 'IS', 'IS', 'IS', 'IS']\n",
      "True\n",
      "['dropout', 'dropout', 'dropout']\n",
      "False\n",
      "['Recurrent Neural Networks', 'Recurrent Neural Networks', 'Recurrent Neural Networks', 'recurrent networks']\n",
      "False\n",
      "['large scale LM', 'large scale LM', 'large scale LM task']\n",
      "False\n",
      "['sampling methods', 'Sampling approaches']\n",
      "False\n",
      "['CNN Softmax', 'CNN Softmax', 'CNN Softmax', 'CNN Softmax', 'CNN Softmax layer', 'CNN Softmax', 'CNN Softmax', 'CNN Softmax sub - network', 'CNN Softmax', 'CNN Softmax']\n",
      "False\n",
      "['importance sampling', 'importance sampling', 'Importance Sampling', 'importance sampling', 'importance sampling', 'importance sampling loss', 'importance sampling', 'Importance Sampling', 'importance sampling']\n",
      "False\n",
      "['character CNN embedding models', 'Character CNN embedding']\n",
      "False\n",
      "['character - level LSTMs', 'character - level LSTM']\n",
      "False\n",
      "['Noise Contrastive Estimation', 'Noise Contrastive Estimation']\n",
      "True\n",
      "['perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexities', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity', 'perplexity']\n",
      "True\n",
      "['count - based LMs', 'count - based LMs']\n",
      "False\n",
      "['large scale modeling', 'large scale Language Modeling']\n",
      "True\n",
      "['speech recognition', 'speech recognition', 'named entity recognition']\n",
      "True\n",
      "['Long - Short Term Memory', 'Long - Short Term Memory model']\n",
      "False\n",
      "['NCE', 'NCE', 'NCE', 'NCE', 'NCE', 'NCE', 'NCE', 'NCE', 'NCE', 'NCE']\n",
      "True\n",
      "['RNNs', 'RNNs', 'RNN', 'RNNs', 'RNN', 'RNN', 'RNN']\n",
      "False\n",
      "['regular', 'regular']\n",
      "False\n",
      "['surrogate binary classification task', 'surrogate classification task', 'binary classification task']\n",
      "False\n",
      "['projection layer', 'projection layers']\n",
      "False\n",
      "['part - of - speech tagging', 'part - of - speech tagging task']\n",
      "True\n",
      "['LSTM', 'LSTM LM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'LSTM model', 'LSTM']\n",
      "False\n",
      "['computer vision', 'computer vision', 'computer vision community']\n",
      "False\n",
      "['Softmax', 'Softmax', 'Softmax', 'Softmax', 'Softmax']\n",
      "False\n",
      "['Model Architecture', 'model architectures']\n",
      "False\n",
      "['model size', 'model size']\n",
      "False\n",
      "['speed', 'training speed', 'Training Speed']\n",
      "False\n",
      "['large scale Language Modeling', 'small - scale language modeling', 'small scale language modeling']\n",
      "True\n",
      "['multiclass classification problem', 'multiclass classification task']\n",
      "False\n",
      "['N - grams', 'N - grams', 'N - grams', 'N - grams', 'N - gram']\n",
      "False\n",
      "['matrix - matrix multiplications']\n",
      "False\n",
      "['Convolutional Embedding Models']\n",
      "False\n",
      "['parametric', 'parametric approaches']\n",
      "False\n",
      "['Assigning probability distributions']\n",
      "False\n",
      "['AdaGrad optimizer']\n",
      "False\n",
      "['Softmax layer', 'Softmax layer', 'Softmax layer']\n",
      "False\n",
      "['PTB', 'PTB', 'PTB', 'PTB', 'PTB data set', 'PTB']\n",
      "True\n",
      "['machine translation', 'machine translation', 'translation', 'machine translation', 'Machine Translation']\n",
      "True\n",
      "['ensemble of models', 'ensembles of models']\n",
      "False\n",
      "['regular word embeddings']\n",
      "False\n",
      "['Neural Networks', 'Neural Network']\n",
      "False\n",
      "['learning rate', 'learning rate', 'learning rate']\n",
      "False\n",
      "['LSTM LM', 'LSTM LMs']\n",
      "False\n",
      "['over - fitting']\n",
      "False\n",
      "['average per - word log - probability']\n",
      "False\n",
      "['LM', 'LMs', 'LM', 'LM', 'LM', 'LMs']\n",
      "False\n",
      "['LSTMs', 'LSTMs', 'LSTMs', 'LSTMs']\n",
      "False\n",
      "['word - embedding sub - network']\n",
      "False\n",
      "['training', 'training', 'parallel training', 'training']\n",
      "False\n",
      "['language understanding', 'Language Understanding', 'language understanding', 'language understanding']\n",
      "False\n",
      "['regularization']\n",
      "False\n",
      "['classifier', 'classifier', 'logistic classifier']\n",
      "False\n",
      "['N - gram models', 'N - gram model', 'N - gram model', 'N - gram models']\n",
      "False\n",
      "['linear layer', 'linear layer']\n",
      "False\n",
      "['RNN LMs', 'RNN LM']\n",
      "False\n",
      "['fine - tuning']\n",
      "False\n",
      "['Hierarchical Softmax', 'Hierarchical Softmax']\n",
      "False\n",
      "['128 dimensional bottleneck embedding']\n",
      "False\n",
      "['word - LSTM']\n",
      "False\n",
      "['KN - 5', 'KN - 5']\n",
      "False\n",
      "['Language Modeling', 'language models', 'language models', 'language models', 'language modeling', 'Language Models', 'Language Modeling', 'Language Modeling']\n",
      "True\n",
      "['RNN LM architectures']\n",
      "False\n",
      "['CNN', 'Character CNN']\n",
      "False\n",
      "['scaling issue']\n",
      "False\n",
      "['truncated BPTT']\n",
      "False\n",
      "['word and character - level models']\n",
      "False\n",
      "['Tesla K40 GPUs']\n",
      "False\n",
      "['network architecture']\n",
      "False\n",
      "['cross - entropy']\n",
      "False\n",
      "['deep learning']\n",
      "False\n",
      "['Kneser - Ney smoothed 5 - gram models']\n",
      "False\n",
      "['downstream task']\n",
      "False\n",
      "['log - linear models']\n",
      "False\n",
      "['early stopping']\n",
      "False\n",
      "['binary task', 'binary task']\n",
      "False\n",
      "['non - parametric approaches']\n",
      "False\n",
      "['semantic representations']\n",
      "False\n",
      "['fixed vocabulary models']\n",
      "False\n",
      "['logistic loss']\n",
      "False\n",
      "['CNN', 'CNN model']\n",
      "False\n",
      "['self normalizing partition functions']\n",
      "False\n",
      "['training recipes']\n",
      "False\n",
      "['chain rule']\n",
      "False\n",
      "['inner product']\n",
      "False\n",
      "['nearest neighbor embeddings']\n",
      "False\n",
      "['large , regularized LSTM LM']\n",
      "False\n",
      "['full Softmax']\n",
      "False\n",
      "['statistics of N - grams']\n",
      "False\n",
      "['computational complexity']\n",
      "False\n",
      "['video generation']\n",
      "False\n",
      "['LMs', 'LM']\n",
      "False\n",
      "['Noise Contrastive Estimation']\n",
      "False\n",
      "['asynchronous gradient updates']\n",
      "False\n",
      "['pre - processing']\n",
      "False\n",
      "['complex vision models']\n",
      "False\n",
      "['Natural Language Processing']\n",
      "False\n",
      "['1 - d CNN']\n",
      "False\n",
      "['Bayes rule']\n",
      "False\n",
      "['BLEU score']\n",
      "True\n",
      "['model predictions']\n",
      "False\n",
      "['training and inference time']\n",
      "False\n",
      "['TensorFlow system']\n",
      "False\n",
      "['embedding layer']\n",
      "False\n",
      "['Deep Learning']\n",
      "False\n",
      "['multiclass loss']\n",
      "False\n",
      "['128 - dim correction']\n",
      "False\n",
      "['word embeddings', 'word embeddings', 'word embedding', 'Word Embeddings', 'word embedding term']\n",
      "False\n",
      "['gating mechanism']\n",
      "False\n",
      "['Regularization Importance']\n",
      "False\n",
      "['parsing']\n",
      "False\n",
      "['Softmax loss']\n",
      "False\n",
      "['character Convolutional Neural Networks']\n",
      "False\n",
      "['IS', 'IS', 'IS']\n",
      "False\n",
      "['word - level Softmax layer']\n",
      "False\n",
      "['cross entropy loss']\n",
      "False\n",
      "['distributed setting']\n",
      "False\n",
      "['conditional language models']\n",
      "False\n",
      "['modeling language']\n",
      "False\n",
      "['large scale RNN - based LMs']\n",
      "False\n",
      "['NN - based LMs']\n",
      "False\n",
      "['2048 unit LSTM']\n",
      "False\n",
      "['Count - based approaches']\n",
      "False\n",
      "['text summarization', 'text summarization']\n",
      "False\n",
      "['large scale Softmax']\n",
      "False\n",
      "['large scale recurrent neural network training']\n",
      "False\n",
      "['smoothing']\n",
      "False\n",
      "['2 - layer LSTM']\n",
      "False\n",
      "['ML community']\n",
      "False\n",
      "['bottleneck linear layer']\n",
      "False\n",
      "['regular Softmax']\n",
      "False\n",
      "['small character CNNs']\n",
      "False\n",
      "['max - pooling']\n",
      "False\n",
      "['human language']\n",
      "True\n",
      "['parametrized neural network']\n",
      "False\n",
      "['Softmax non - linearity']\n",
      "False\n",
      "['sequence - to - sequence models']\n",
      "False\n",
      "['Penn Tree Bank']\n",
      "True\n",
      "['small tasks']\n",
      "False\n",
      "['word - level LSTM hidden state']\n",
      "False\n",
      "['2 - layer highway network']\n",
      "False\n",
      "['bidirectional LSTMs']\n",
      "False\n",
      "['Recurrent Neural Networks based LMs']\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for p, v in doc['predicted_clusters'].items() :\n",
    "    print([\" \".join(doc['words'][x[0]:x[1]]) for x in v])\n",
    "    print(p in doc['linked_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02b3d1d162080d9aefd3fc30a0bcc9a843073b5d'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
