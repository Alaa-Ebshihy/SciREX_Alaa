{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dygie.commands.generate_metrics import load_documents, update_documents_with_clusters, update_documents_with_spans, load_jsonl\n",
    "from collections import namedtuple\n",
    "\n",
    "from collections import namedtuple\n",
    "def convert(dictionary):\n",
    "    return namedtuple('GenericDict', dictionary.keys())(**dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "5\n",
      "5\n",
      "9\n",
      "10\n",
      "7\n",
      "7\n",
      "3\n",
      "10\n",
      "10\n",
      "6\n",
      "4\n",
      "9\n",
      "8\n",
      "3\n",
      "2\n",
      "8\n",
      "10\n",
      "9\n",
      "9\n",
      "13\n",
      "17\n",
      "4\n",
      "5\n",
      "8\n",
      "12\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "10\n",
      "6\n",
      "3\n",
      "12\n",
      "13\n",
      "13\n",
      "8\n",
      "9\n",
      "9\n",
      "16\n",
      "5\n",
      "7\n",
      "10\n",
      "8\n",
      "17\n",
      "9\n",
      "10\n",
      "6\n",
      "5\n",
      "2\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "7\n",
      "7\n",
      "6\n",
      "10\n",
      "8\n",
      "17\n",
      "12\n",
      "16\n",
      "8\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for d in documents.values() :\n",
    "    print(len(d['linked_clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Exact F1 &  Exact P &  Exact R &  Soft F1 &  Soft P &  Soft R \\\\\n",
      "\\midrule\n",
      "Method   &     0.784 &    0.779 &    0.789 &    0.847 &   0.841 &   0.852 \\\\\n",
      "Task     &     0.707 &    0.705 &    0.709 &    0.779 &   0.779 &   0.779 \\\\\n",
      "Metric   &     0.741 &    0.741 &    0.741 &    0.821 &   0.821 &   0.821 \\\\\n",
      "Material &     0.562 &    0.553 &    0.570 &    0.644 &   0.633 &   0.656 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "macro_p             0.248911\n",
      "macro_r             0.349521\n",
      "macro_overlap_p     0.426247\n",
      "macro_overlap_r     0.505643\n",
      "macro_f1            0.290758\n",
      "macro_overlap_f1    0.462563\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "documents = load_documents('../model_data/pwc_split_on_sectioned/dev.jsonl')\n",
    "documents = update_documents_with_spans(documents, '../outputs/test_outputs/spans.jsonl', convert({'gold' : False}))\n",
    "documents = update_documents_with_clusters(documents, '../outputs/test_outputs/clusters.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_jsonl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for d in documents :\n",
    "    s.append(len(documents[d]['coref']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.454545454545454"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s)/len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02567fd428a675ca91a0c6786f47f3e35881bcbd\n",
      "{'Age_Estimation', 'MORPH_Album2', 'MAE', 'ChaLearn_2015', 'DLDL', 'VGG-Face'}\n",
      "{'DLDL', 'Age_Estimation', 'ChaLearn_2015', 'MAE'}\n",
      "====================\n",
      "02b3d1d162080d9aefd3fc30a0bcc9a843073b5d\n",
      "{'LSTM-8192-1024___CNN_Input', 'LSTM-8192-1024', 'CNN_Input', 'One_Billion_Word', 'Language_Modelling'}\n",
      "{'One_Billion_Word'}\n",
      "====================\n",
      "0398552184f80db111e9c28bf533b395f233ac00\n",
      "{'Self-paced_curriculum_learning', 'Weakly_Supervised_Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'PASCAL_VOC_2007', 'Weakly_Supervised_Object_Detection'}\n",
      "====================\n",
      "05d2700846c0323f79c1344aca5333994c7c03a5\n",
      "{'swb_hub_500_WER_fullSWBCH', '_model_M_', 'VGG', 'Speech_Recognition', 'CH__N-gram', 'Percentage_error', 'LSTM_acoustic_model_trained_on_SWB', 'NNLM_language_model', 'RNN', 'Switchboard___Hub500', 'RNN___VGG___LSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram____model_M____NNLM_language_model'}\n",
      "{'Percentage_error', 'Switchboard___Hub500', 'Speech_Recognition', 'swb_hub_500_WER_fullSWBCH'}\n",
      "====================\n",
      "0626908dd710b91aece1a81f4ca0635f23fc47f3\n",
      "{'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'Inception_V3', 'Image_Classification'}\n",
      "{'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'Inception_V3', 'Image_Classification'}\n",
      "====================\n",
      "0678a8abea82793993cd89383319da75f6dc4be3\n",
      "{'MAP', 'ProNet', 'COCO', 'Weakly_Supervised_Object_Detection'}\n",
      "{'MAP', 'ProNet', 'COCO'}\n",
      "====================\n",
      "081531984770a74e87dbd68907061b4b0f3631bf\n",
      "{'Vid4_-_4x_upscaling', 'MOVIE', 'SSIM', 'VESPCN', 'Video_Super-Resolution', 'PSNR', 'bicubic'}\n",
      "{'Vid4_-_4x_upscaling', 'MOVIE', 'SSIM', 'Video_Super-Resolution', 'PSNR'}\n",
      "====================\n",
      "0834e74304b547c9354b6d7da6fa78ef47a48fa8\n",
      "{'Node_Classification', 'LINE', 'Wikipedia', 'Macro-F1'}\n",
      "{'Node_Classification', 'Macro-F1'}\n",
      "====================\n",
      "0a3381f0432c5cfe491c718349d7a44e5814592c\n",
      "{'Bi-LSTM', 'CoNLL-2014_A2', 'FCE', 'Grammatical_Error_Detection', 'CoNLL-2014_A1'}\n",
      "{'CoNLL-2014_A1', 'FCE', 'Grammatical_Error_Detection'}\n",
      "====================\n",
      "0a6c36de8726b6feaab586046ddc1d1a008f44f9\n",
      "{'Pedestrian_Detection', 'Checkerboards_', 'Caltech', 'Reasonable_Miss_Rate'}\n",
      "{'Pedestrian_Detection', 'Caltech', 'Reasonable_Miss_Rate'}\n",
      "====================\n",
      "0c47cad9729c38d9db1f75491b1ee4bd883a5d4e\n",
      "{'CoNLL_2003__English_', 'Multi-Task', 'Dependency_Parsing', 'POS', 'Accuracy', 'CCG_Supertagging', 'Ontonotes_v5__English_', 'Penn_Treebank', 'Named_Entity_Recognition__NER_', 'CCGBank', 'CVT'}\n",
      "{'Penn_Treebank', 'Accuracy'}\n",
      "====================\n",
      "0dc9eb7d17f2def56ad930945f2521653f04c3fa\n",
      "{'PPL', 'Number_of_params', 'Sparse_Non-Negative', 'One_Billion_Word', 'Language_Modelling'}\n",
      "{'Sparse_Non-Negative', 'PPL', 'One_Billion_Word'}\n",
      "====================\n",
      "107010b7f2abe3c0c9df62bcef35eb77f6fc76df\n",
      "{'DANN', 'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "{'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "====================\n",
      "1130d8fdd931225c2d7563c3808367726cfa1c3a\n",
      "{'PixelGAN_Autoencoders', 'Unsupervised_MNIST', 'MNIST', 'Unsupervised_image_classification'}\n",
      "{'PixelGAN_Autoencoders', 'MNIST', 'Unsupervised_image_classification'}\n",
      "====================\n",
      "11356cd6bb0f2776a88cd584ff108470414c6594\n",
      "{'SSCN'}\n",
      "set()\n",
      "====================\n",
      "11da0c54ba904a1cb31a09d10da55f73e8825c61\n",
      "{'Natural_Language_Inference', '__Test_Accuracy', '300D_Tree-based_CNN_encoders', 'SNLI'}\n",
      "{'Natural_Language_Inference', 'SNLI'}\n",
      "====================\n",
      "1235dd37312cb20aced0e97d953f6379d8a0c7d4\n",
      "{'BiMPM', 'V-SNLI', 'Accuracy', 'Natural_Language_Inference', 'V-BiMPM'}\n",
      "{'Accuracy', 'V-SNLI'}\n",
      "====================\n",
      "14318685b5959b51d0f1e3db34643eb2855dc6d9\n",
      "{'Inception_V1', 'Top_1_Accuracy', 'ImageNet', 'Top_5_Accuracy', 'MAP', 'Image_Classification', 'Object_Detection'}\n",
      "{'MAP', 'Image_Classification', 'Top_1_Accuracy', 'Top_5_Accuracy'}\n",
      "====================\n",
      "16051bbe3a7f7c77a952ebf76722ea655e8906ca\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'FAFR_', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR', 'FARF_'}\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'PSNR', 'FARF_'}\n",
      "====================\n",
      "160563abbd75265b19afc8b4169bab9e1eb33d97\n",
      "{'MLDoc_Zero-Shot_English-to-Spanish', 'BUCC_French-to-English', 'MLDoc_Zero-Shot_English-to-German', 'Accuracy', 'Massively_Multilingual_Sentence_Embeddings', 'XNLI_Zero-Shot_English-to-German', 'Cross-Lingual_Document_Classification', 'Cross-Lingual_Bitext_Mining', 'XNLI_Zero-Shot_English-to-French', 'BiLSTM', 'MLDoc_Zero-Shot_English-to-French', 'BUCC_German-to-English', 'Cross-Lingual_Natural_Language_Inference', 'XNLI_Zero-Shot_English-to-Spanish'}\n",
      "{'BUCC_French-to-English', 'Accuracy', 'Massively_Multilingual_Sentence_Embeddings', 'XNLI_Zero-Shot_English-to-German', 'XNLI_Zero-Shot_English-to-French', 'BUCC_German-to-English', 'XNLI_Zero-Shot_English-to-Spanish'}\n",
      "====================\n",
      "175f74a09241b6cb5101a2a09978095720db7d5f\n",
      "{'Urban100_-_4x_upscaling', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'DSRN', 'PSNR'}\n",
      "{'Urban100_-_4x_upscaling', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'DSRN', 'PSNR'}\n",
      "====================\n",
      "1778e32c18bd611169e64c1805a51abff341ca53\n",
      "{'Accuracy', 'Ensemble', 'DIIN', 'Paraphrase_Identification', 'Quora_Question_Pairs', '448D_Densely_Interactive_Inference_Network', 'SNLI', 'Natural_Language_Inference'}\n",
      "{'Accuracy', 'Paraphrase_Identification', 'DIIN', 'Quora_Question_Pairs', 'SNLI', 'Natural_Language_Inference'}\n",
      "====================\n",
      "178275dbdcfa267e41a9d5efe386ee5874c6d23f\n",
      "{'WikiText-2', 'AWD-LSTM_3-layer_with_Fraternal_dropout', 'Penn_Treebank__Word_Level_', 'Validation_perplexity', 'Test_perplexity', 'Language_Modelling'}\n",
      "{'Language_Modelling', 'Penn_Treebank__Word_Level_', 'WikiText-2'}\n",
      "====================\n",
      "178631e0f0e624b1607c7a7a2507ed30d4e83a42\n",
      "{'Bi-LSTM', 'Speech_Recognition', 'TIMIT', 'Percentage_error'}\n",
      "{'Percentage_error', 'Speech_Recognition', 'TIMIT'}\n",
      "====================\n",
      "18168aea48a22f6fe2fe407c0ff70083cba225a7\n",
      "{'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'RED30', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "{'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'SSIM', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "====================\n",
      "193089d56758ab88391d846edd08d359b1f9a863\n",
      "{'Rank-1', 'DLCE', 'MAP', 'Market-1501', 'Person_Re-Identification'}\n",
      "{'Person_Re-Identification', 'Market-1501', 'Rank-1', 'MAP'}\n",
      "====================\n",
      "193b518bc3025804c6d587c74cbc154d91478417\n",
      "{'Synthetic-to-Real_Translation', 'Single-level_Adaptation', 'mIoU'}\n",
      "{'mIoU'}\n",
      "====================\n",
      "1d0dcb458aa4d30b51f7c74b159be687f39120a0\n",
      "{'MAP', 'Market-1501', 'Person_Re-Identification', 'Rank-1'}\n",
      "{'Person_Re-Identification', 'Rank-1', 'MAP'}\n",
      "====================\n",
      "1f08598381af9146d0fd9a61b30d0e51a7331689\n",
      "{'Ape-X', 'Atari_Games', 'Medium_Human-Normalized_Score'}\n",
      "{'Ape-X', 'Atari_Games', 'Medium_Human-Normalized_Score'}\n",
      "====================\n",
      "2138a7127429d67746ec78de46d6820fee0e548e\n",
      "{'Graph2Seq-PGE', 'SQL-to-Text', 'WikiSQL', 'BLEU-4'}\n",
      "{'BLEU-4'}\n",
      "====================\n",
      "21a1654b856cf0c64e60e58258669b374cb05539\n",
      "{'YOLO', 'PASCAL_VOC_2007', 'MAP', 'Real-Time_Object_Detection', 'Object_Detection', 'FPS'}\n",
      "{'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "232b43584b2236669c0a53702ad89ab10c3886ea\n",
      "{'Score', 'Atari_Games', 'Atari_2600_Assault', 'Atari_2600_Breakout', 'Atari_2600_James_Bond', 'Atari_2600_Q_Bert', 'Atari_2600_Space_Invaders', 'IQN', 'Atari_2600_Asterix'}\n",
      "{'Score', 'Atari_2600_James_Bond', 'Atari_Games'}\n",
      "====================\n",
      "23d2d3a6ffebfecaa8930307fdcf451c147757c8\n",
      "{'SeqGAN', 'BLEU-2', 'Text_Generation', 'Chinese_Poems', 'BLEU-4', 'BLEU-3'}\n",
      "{'SeqGAN'}\n",
      "====================\n",
      "24730424236724d3f798dec02901e7a1f1c4710e\n",
      "{'JMPF', 'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR', 'JMPF_'}\n",
      "{'Set14_-_4x_upscaling', 'Image_Super-Resolution', 'BSD100_-_4x_upscaling', 'Set5_-_4x_upscaling', 'PSNR'}\n",
      "====================\n",
      "249b3b7421d3cdb932eecfe4b67203e0e46806b2\n",
      "{'SST-2_Binary_classification', 'Bi-CAS-LSTM', 'Accuracy', 'Paraphrase_Identification', 'Quora_Question_Pairs', 'SST-5_Fine-grained_classification', 'SNLI', 'Sentiment_Analysis', 'Natural_Language_Inference'}\n",
      "{'SST-2_Binary_classification', 'Accuracy', 'Paraphrase_Identification', 'Quora_Question_Pairs', 'SST-5_Fine-grained_classification', 'SNLI', 'Sentiment_Analysis', 'Natural_Language_Inference'}\n",
      "====================\n",
      "25a784f7f8c94c42821ee078587fc38dffcd00a4\n",
      "{'AP', 'Annotated_Faces_in_the_Wild', 'WIDER_Face__Hard_', 'Face_Detection', 'FDDB', 'PASCAL_Face', 'Anchor-based'}\n",
      "{'AP', 'Annotated_Faces_in_the_Wild', 'WIDER_Face__Hard_', 'Face_Detection', 'FDDB', 'PASCAL_Face'}\n",
      "====================\n",
      "25f5df29342a04936ba0d308b4d1b8245a7e8f5c\n",
      "{'Convolutional_Pose_Machines', 'FLIC_Wrists', 'Pose_Estimation', 'PCK_0_2', 'PCK', 'PCKh-0_5', 'FLIC_Elbows', 'Leeds_Sports_Poses', 'MPII_Human_Pose'}\n",
      "{'MPII_Human_Pose', 'FLIC_Wrists', 'PCK_0_2', 'PCK', 'PCKh-0_5', 'Leeds_Sports_Poses', 'FLIC_Elbows'}\n",
      "====================\n",
      "269730dbbabed8b8b5ba720e44a4c31b1f51e8f1\n",
      "{'bAbi', 'QRN', 'Mean_Error_Rate', 'Question_Answering'}\n",
      "{'bAbi', 'Mean_Error_Rate', 'Question_Answering'}\n",
      "====================\n",
      "270e65acc071b9e4e2a632720130c0e10cb6fa08\n",
      "{'Natural_Language_Inference', '__Test_Accuracy', 'SNLI', '300D_NTI-SLSTM-LSTM_encoders'}\n",
      "{'Natural_Language_Inference', 'SNLI'}\n",
      "====================\n",
      "2777cd26b2c257843273fe41ad4c5b8cdf1b1b75\n",
      "{'NAN', 'PASCAL-Person-Part', 'Multi-Human_Parsing', 'MHP_v1_0', 'MHP_v2_0'}\n",
      "{'NAN', 'PASCAL-Person-Part', 'Multi-Human_Parsing', 'MHP_v1_0', 'MHP_v2_0'}\n",
      "====================\n",
      "27a99c21a1324f087b2f144adc119f04137dfd87\n",
      "{'Percentage_error', 'MNIST', 'Deep_Fried_Convnets'}\n",
      "{'Percentage_error', 'MNIST'}\n",
      "====================\n",
      "27aa0f3ec934925265f93fac7ff1cd1d70ceb618\n",
      "{'Average', 'Multi-task_tri-training', 'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "{'Multi-Domain_Sentiment_Dataset', 'Sentiment_Analysis'}\n",
      "====================\n",
      "2a86bcdfb1d817ddb76ba202319f8267a36c0f62\n",
      "{'ImageNet', 'Weakly_Supervised_Object_Detection', 'PCL-OB-G-Ens', 'PASCAL_VOC_2012', 'FRCNN', 'PASCAL_VOC_2007', 'MAP', 'PCL-OB-G-Ens___FRCNN'}\n",
      "{'MAP', 'PASCAL_VOC_2012', 'Weakly_Supervised_Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "2f04ba0f74df046b0080ca78e56898bd4847898b\n",
      "{'AP', 'ACF-WIDER', 'Face_Detection'}\n",
      "{'ACF-WIDER', 'Face_Detection'}\n",
      "====================\n",
      "2f56b1ac5b9faac9527b6814778925e9242cf5fd\n",
      "{'OHEM', 'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'OHEM', 'MAP', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "2f97ee95cad6a1f13596b108072b846c6f747d4e\n",
      "{'RNNLM_language_model_trained_on_Switchboard', 'VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB', 'Speech_Recognition', 'CH__N-gram', 'Percentage_error', 'VGG_Resnet_LACE_BiLSTM_acoustic_model_trained_on_SWB_Fisher_CH__N-gram___RNNLM_language_model_trained_on_Switchboard_Fisher_Gigaword_Broadcast', 'Switchboard___Hub500', 'RNNLM'}\n",
      "{'Percentage_error', 'Switchboard___Hub500', 'Speech_Recognition'}\n",
      "====================\n",
      "322a7dad274f440a92548faa8f2b2be666b2d01f\n",
      "{'mIoU', 'PSPNet', 'PASCAL_VOC_2012', 'ADE20K', 'Cityscapes', 'Test_Score', 'Mean_IoU', 'Semantic_Segmentation'}\n",
      "{'PASCAL_VOC_2012', 'ADE20K', 'Cityscapes', 'Mean_IoU', 'mIoU'}\n",
      "====================\n",
      "325af39d281d5903a269c01fab8f53d7400a4c49\n",
      "{'AP', 'Articulated_Tracking', 'MPII_Multi-Person', 'Multi-Person_Pose_Estimation'}\n",
      "{'MPII_Multi-Person', 'AP', 'Multi-Person_Pose_Estimation'}\n",
      "====================\n",
      "33261d252218007147a71e40f8367ed152fa2fe0\n",
      "{'Subgraph_embeddings', 'Question_Answering', 'WebQuestions', 'F1'}\n",
      "{'Question_Answering'}\n",
      "====================\n",
      "3448e6a5039417dc1ae890efeca3bef5390ace7c\n",
      "{'Criteo', 'Dianping', 'AUC', 'Click-Through_Rate_Prediction', 'Bing_News', 'Log_Loss', 'xDeepFM'}\n",
      "{'Bing_News', 'xDeepFM'}\n",
      "====================\n",
      "35734e8724559fb0d494e5cba6a28ad7a3d5dd4d\n",
      "{'Percentage_error', 'Explaining_and_Harnessing_Adversarial_Examples', 'Image_Classification', 'MNIST'}\n",
      "{'Percentage_error', 'MNIST'}\n",
      "====================\n",
      "364c1a3df58d87cb40ab33fdf3831cf2862f3570\n",
      "{'aNMM', 'MAP', 'MRR', 'TrecQA', 'Question_Answering'}\n",
      "{'MAP', 'MRR', 'Question_Answering', 'TrecQA'}\n",
      "====================\n",
      "3842ee1e0fdfeff936b5c49973ff21adfaaf3929\n",
      "{'Unsupervised_Image-To-Image_Translation', 'SVNH-to-MNIST', 'ADDA', 'Classification_Accuracy'}\n",
      "{'Classification_Accuracy', 'SVNH-to-MNIST'}\n",
      "====================\n",
      "38cc89399dd6f5aaab1654f27ab3c9eeade12a36\n",
      "{'Average_3D_Error', '3D_Human_Pose_Estimation', 'Sequence-to-sequence_network_', 'Human3_6M'}\n",
      "{'Average_3D_Error', 'Human3_6M'}\n",
      "====================\n",
      "38e2f851b705faa0d0a698ed9885bd6834440073\n",
      "{'PLATIPUS', 'Few-Shot_Image_Classification', 'Mini-ImageNet_-_1-Shot_Learning', 'Accuracy'}\n",
      "{'Mini-ImageNet_-_1-Shot_Learning', 'Accuracy'}\n",
      "====================\n",
      "3aa21de1a7c97e0458e10ed5730ce160bb436caa\n",
      "{'Avg_F1', '3D_Object_Reconstruction', 'Data3D_R2N2', 'Pixel2Mesh'}\n",
      "{'Avg_F1'}\n",
      "====================\n",
      "3acc07f7f8951617276cf99483ed02aeb0a6eeac\n",
      "{'GTAV-to-Cityscapes_Labels', 'CDA', 'mIoU'}\n",
      "{'GTAV-to-Cityscapes_Labels', 'mIoU'}\n",
      "====================\n",
      "3ca3993b1f3536b15112f759067f62e999c5d38f\n",
      "{'BB8', 'LineMOD', 'Accuracy'}\n",
      "{'LineMOD'}\n",
      "====================\n",
      "3cf31ecb2724b5088783d7c96a5fc0d5604cbf41\n",
      "{'UAS', 'POS', 'BIST_graph-based_parser', 'BIST_transition-based_parser', 'Penn_Treebank', 'Dependency_Parsing', 'LAS'}\n",
      "{'UAS', 'Dependency_Parsing'}\n",
      "====================\n",
      "3daa086acd367dc971a2dc1382caba2031294233\n",
      "{'Holistic_instance-level', 'AP_0_5', 'Multi-Human_Parsing', 'PASCAL-Person-Part'}\n",
      "{'Holistic_instance-level', 'AP_0_5', 'PASCAL-Person-Part'}\n",
      "====================\n",
      "408e8eecc14c5cc60bbdfc486ba7a7fc97031788\n",
      "{'CIFAR-10', 'Image_Classification', 'Discriminative_Unsupervised_Feature_Learning_with_Convolutional_Neural_Networks', 'STL-10'}\n",
      "{'CIFAR-10', 'Image_Classification', 'STL-10'}\n",
      "====================\n",
      "4365eb43a635bc6431dfaf3af1f7bf7bf55522cc\n",
      "{'MAP', 'CoupleNet', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "{'MAP', 'CoupleNet', 'Object_Detection', 'PASCAL_VOC_2007'}\n",
      "====================\n",
      "436b07bebaa1d1f05ef85415e10374048d25334d\n",
      "{'PPL', 'Machine_Translation', 'Number_of_params', 'MoE', 'WMT2014_English-French', 'WMT2014_English-German', 'One_Billion_Word', 'BLEU_score', 'Language_Modelling'}\n",
      "{'PPL', 'Machine_Translation', 'WMT2014_English-French', 'MoE', 'WMT2014_English-German', 'One_Billion_Word', 'BLEU_score', 'Language_Modelling'}\n",
      "====================\n",
      "44078d0daed8b13114cffb15b368acc467f96351\n",
      "{'IJB-A', 'Triplet_probabilistic_embedding', 'TAR___FAR_0_01', 'Face_Verification'}\n",
      "{'IJB-A', 'TAR___FAR_0_01', 'Face_Verification'}\n",
      "====================\n",
      "45429c281e30f9e87ebcd1ae42e0656d2ead24d1\n",
      "{'ADE20K_Labels-to-Photos', 'Cityscapes_Labels-to-Photo', 'Accuracy', 'Image-to-Image_Translation', 'pix2pixHD', 'ADE20K-Outdoor_Labels-to-Photos', 'Class_IOU'}\n",
      "{'ADE20K_Labels-to-Photos', 'pix2pixHD', 'Cityscapes_Labels-to-Photo', 'Class_IOU'}\n",
      "====================\n",
      "455da02e5048dffb51fb6ab5eb8aeca5926c9d9a\n",
      "{'SPP', 'PASCAL_VOC_2007', 'MAP', 'Object_Detection', 'Overfeat-7'}\n",
      "{'MAP', 'SPP', 'PASCAL_VOC_2007'}\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for d in documents :\n",
    "    print(d)\n",
    "    print(set(list(documents[d]['coref'].keys())))\n",
    "    print(set([x for k,v in documents[d]['intersection_scores'].items() for x, _ in v.items()]))\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_clustering = []\n",
    "for d in documents :\n",
    "    n_clusters_clustering.append(len(documents[d]['predicted_clusters']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_clusters_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['NLP']\n",
      "['NLP']\n",
      "['NLP', 'tasks']\n",
      "['NLP']\n",
      "['NLP', 'problems']\n",
      "==========\n",
      "1\n",
      "['character', 'level', 'CNNs']\n",
      "['character', 'embedding', 'CNNs']\n",
      "['character', 'CNNs']\n",
      "==========\n",
      "2\n",
      "['low', 'perplexity', 'LMs']\n",
      "['perplexity']\n",
      "==========\n",
      "3\n",
      "['single', 'layer', 'LSTM']\n",
      "['single', '-', 'layer', 'LSTM', 'of', '1024', 'units']\n",
      "==========\n",
      "4\n",
      "['language', 'modeling']\n",
      "['Language', 'Modeling']\n",
      "['language', 'modeling']\n",
      "['neural', 'language', 'modeling']\n",
      "['language', 'modeling']\n",
      "['language', 'modeling']\n",
      "['statistical', 'language', 'modeling']\n",
      "['language', 'modeling']\n",
      "['Language', 'Modeling']\n",
      "==========\n",
      "5\n",
      "['question', 'answering']\n",
      "['inference']\n",
      "['inference']\n",
      "['inference']\n",
      "==========\n",
      "6\n",
      "['One', 'Billion', 'Word', 'Benchmark']\n",
      "['One', 'Billion', 'Word', 'Benchmark', 'data', 'set']\n",
      "['One', 'Billion', 'Word', 'Benchmark']\n",
      "['1B', 'Word', 'Benchmark', 'data', 'set']\n",
      "['1B', 'Word', 'Benchmark', 'data', 'set']\n",
      "Linked\n",
      "==========\n",
      "7\n",
      "['CNN', 'character', 'embeddings']\n",
      "['character', '-', 'level', 'embeddings']\n",
      "['character', '-', 'level', 'embeddings']\n",
      "==========\n",
      "8\n",
      "['word', 'error', 'rate']\n",
      "['IS']\n",
      "['IS']\n",
      "['IS']\n",
      "['IS']\n",
      "['IS']\n",
      "==========\n",
      "9\n",
      "['dropout']\n",
      "['dropout']\n",
      "['dropout']\n",
      "==========\n",
      "10\n",
      "['Recurrent', 'Neural', 'Networks']\n",
      "['Recurrent', 'Neural', 'Networks']\n",
      "['Recurrent', 'Neural', 'Networks']\n",
      "['recurrent', 'networks']\n",
      "==========\n",
      "11\n",
      "['large', 'scale', 'LM']\n",
      "['large', 'scale', 'LM']\n",
      "['large', 'scale', 'LM', 'task']\n",
      "==========\n",
      "12\n",
      "['sampling', 'methods']\n",
      "['Sampling', 'approaches']\n",
      "==========\n",
      "13\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax', 'layer']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax', 'sub', '-', 'network']\n",
      "['CNN', 'Softmax']\n",
      "['CNN', 'Softmax']\n",
      "==========\n",
      "14\n",
      "['importance', 'sampling']\n",
      "['importance', 'sampling']\n",
      "['Importance', 'Sampling']\n",
      "['importance', 'sampling']\n",
      "['importance', 'sampling']\n",
      "['importance', 'sampling', 'loss']\n",
      "['importance', 'sampling']\n",
      "['Importance', 'Sampling']\n",
      "['importance', 'sampling']\n",
      "==========\n",
      "15\n",
      "['character', 'CNN', 'embedding', 'models']\n",
      "['Character', 'CNN', 'embedding']\n",
      "==========\n",
      "16\n",
      "['character', '-', 'level', 'LSTMs']\n",
      "['character', '-', 'level', 'LSTM']\n",
      "==========\n",
      "17\n",
      "['Noise', 'Contrastive', 'Estimation']\n",
      "['Noise', 'Contrastive', 'Estimation']\n",
      "==========\n",
      "18\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexities']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "['perplexity']\n",
      "Linked\n",
      "==========\n",
      "19\n",
      "['count', '-', 'based', 'LMs']\n",
      "['count', '-', 'based', 'LMs']\n",
      "==========\n",
      "20\n",
      "['large', 'scale', 'modeling']\n",
      "['large', 'scale', 'Language', 'Modeling']\n",
      "==========\n",
      "21\n",
      "['speech', 'recognition']\n",
      "['speech', 'recognition']\n",
      "['named', 'entity', 'recognition']\n",
      "==========\n",
      "22\n",
      "['Long', '-', 'Short', 'Term', 'Memory']\n",
      "['Long', '-', 'Short', 'Term', 'Memory', 'model']\n",
      "==========\n",
      "23\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "['NCE']\n",
      "==========\n",
      "24\n",
      "['RNNs']\n",
      "['RNNs']\n",
      "['RNN']\n",
      "['RNNs']\n",
      "['RNN']\n",
      "['RNN']\n",
      "['RNN']\n",
      "==========\n",
      "25\n",
      "['regular']\n",
      "['regular']\n",
      "==========\n",
      "26\n",
      "['surrogate', 'binary', 'classification', 'task']\n",
      "['surrogate', 'classification', 'task']\n",
      "['binary', 'classification', 'task']\n",
      "==========\n",
      "27\n",
      "['projection', 'layer']\n",
      "['projection', 'layers']\n",
      "==========\n",
      "28\n",
      "['part', '-', 'of', '-', 'speech', 'tagging']\n",
      "['part', '-', 'of', '-', 'speech', 'tagging', 'task']\n",
      "==========\n",
      "29\n",
      "['LSTM']\n",
      "['LSTM', 'LM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM']\n",
      "['LSTM', 'model']\n",
      "['LSTM']\n",
      "==========\n",
      "30\n",
      "['computer', 'vision']\n",
      "['computer', 'vision']\n",
      "['computer', 'vision', 'community']\n",
      "==========\n",
      "31\n",
      "['Softmax']\n",
      "['Softmax']\n",
      "['Softmax']\n",
      "['Softmax']\n",
      "['Softmax']\n",
      "==========\n",
      "32\n",
      "['Model', 'Architecture']\n",
      "['model', 'architectures']\n",
      "==========\n",
      "33\n",
      "['model', 'size']\n",
      "['model', 'size']\n",
      "==========\n",
      "34\n",
      "['speed']\n",
      "['training', 'speed']\n",
      "['Training', 'Speed']\n",
      "==========\n",
      "35\n",
      "['large', 'scale', 'Language', 'Modeling']\n",
      "['small', '-', 'scale', 'language', 'modeling']\n",
      "['small', 'scale', 'language', 'modeling']\n",
      "==========\n",
      "36\n",
      "['multiclass', 'classification', 'problem']\n",
      "['multiclass', 'classification', 'task']\n",
      "==========\n",
      "37\n",
      "['N', '-', 'grams']\n",
      "['N', '-', 'grams']\n",
      "['N', '-', 'grams']\n",
      "['N', '-', 'grams']\n",
      "['N', '-', 'gram']\n",
      "==========\n",
      "38\n",
      "['matrix', '-', 'matrix', 'multiplications']\n",
      "==========\n",
      "39\n",
      "['Convolutional', 'Embedding', 'Models']\n",
      "==========\n",
      "40\n",
      "['parametric']\n",
      "['parametric', 'approaches']\n",
      "==========\n",
      "41\n",
      "['Assigning', 'probability', 'distributions']\n",
      "==========\n",
      "42\n",
      "['AdaGrad', 'optimizer']\n",
      "==========\n",
      "43\n",
      "['Softmax', 'layer']\n",
      "['Softmax', 'layer']\n",
      "['Softmax', 'layer']\n",
      "==========\n",
      "44\n",
      "['PTB']\n",
      "['PTB']\n",
      "['PTB']\n",
      "['PTB']\n",
      "['PTB', 'data', 'set']\n",
      "['PTB']\n",
      "Linked\n",
      "==========\n",
      "45\n",
      "['machine', 'translation']\n",
      "['machine', 'translation']\n",
      "['translation']\n",
      "['machine', 'translation']\n",
      "['Machine', 'Translation']\n",
      "==========\n",
      "46\n",
      "['ensemble', 'of', 'models']\n",
      "['ensembles', 'of', 'models']\n",
      "==========\n",
      "47\n",
      "['regular', 'word', 'embeddings']\n",
      "==========\n",
      "48\n",
      "['Neural', 'Networks']\n",
      "['Neural', 'Network']\n",
      "==========\n",
      "49\n",
      "['learning', 'rate']\n",
      "['learning', 'rate']\n",
      "['learning', 'rate']\n",
      "==========\n",
      "50\n",
      "['LSTM', 'LM']\n",
      "['LSTM', 'LMs']\n",
      "==========\n",
      "51\n",
      "['over', '-', 'fitting']\n",
      "==========\n",
      "52\n",
      "['average', 'per', '-', 'word', 'log', '-', 'probability']\n",
      "Linked\n",
      "==========\n",
      "53\n",
      "['LM']\n",
      "['LMs']\n",
      "['LM']\n",
      "['LM']\n",
      "['LM']\n",
      "['LMs']\n",
      "==========\n",
      "54\n",
      "['LSTMs']\n",
      "['LSTMs']\n",
      "['LSTMs']\n",
      "['LSTMs']\n",
      "==========\n",
      "55\n",
      "['word', '-', 'embedding', 'sub', '-', 'network']\n",
      "==========\n",
      "56\n",
      "['training']\n",
      "['training']\n",
      "['parallel', 'training']\n",
      "['training']\n",
      "==========\n",
      "57\n",
      "['language', 'understanding']\n",
      "['Language', 'Understanding']\n",
      "['language', 'understanding']\n",
      "['language', 'understanding']\n",
      "==========\n",
      "58\n",
      "['regularization']\n",
      "==========\n",
      "59\n",
      "['classifier']\n",
      "['classifier']\n",
      "['logistic', 'classifier']\n",
      "==========\n",
      "60\n",
      "['N', '-', 'gram', 'models']\n",
      "['N', '-', 'gram', 'model']\n",
      "['N', '-', 'gram', 'model']\n",
      "['N', '-', 'gram', 'models']\n",
      "==========\n",
      "61\n",
      "['linear', 'layer']\n",
      "['linear', 'layer']\n",
      "==========\n",
      "62\n",
      "['RNN', 'LMs']\n",
      "['RNN', 'LM']\n",
      "==========\n",
      "63\n",
      "['fine', '-', 'tuning']\n",
      "==========\n",
      "64\n",
      "['Hierarchical', 'Softmax']\n",
      "['Hierarchical', 'Softmax']\n",
      "==========\n",
      "65\n",
      "['128', 'dimensional', 'bottleneck', 'embedding']\n",
      "==========\n",
      "66\n",
      "['word', '-', 'LSTM']\n",
      "==========\n",
      "67\n",
      "['KN', '-', '5']\n",
      "['KN', '-', '5']\n",
      "==========\n",
      "68\n",
      "['Language', 'Modeling']\n",
      "['language', 'models']\n",
      "['language', 'models']\n",
      "['language', 'models']\n",
      "['language', 'modeling']\n",
      "['Language', 'Models']\n",
      "['Language', 'Modeling']\n",
      "['Language', 'Modeling']\n",
      "==========\n",
      "69\n",
      "['RNN', 'LM', 'architectures']\n",
      "==========\n",
      "70\n",
      "['CNN']\n",
      "['Character', 'CNN']\n",
      "==========\n",
      "71\n",
      "['scaling', 'issue']\n",
      "==========\n",
      "72\n",
      "['truncated', 'BPTT']\n",
      "==========\n",
      "73\n",
      "['word', 'and', 'character', '-', 'level', 'models']\n",
      "==========\n",
      "74\n",
      "['Tesla', 'K40', 'GPUs']\n",
      "==========\n",
      "75\n",
      "['network', 'architecture']\n",
      "==========\n",
      "76\n",
      "['cross', '-', 'entropy']\n",
      "==========\n",
      "77\n",
      "['deep', 'learning']\n",
      "==========\n",
      "78\n",
      "['Kneser', '-', 'Ney', 'smoothed', '5', '-', 'gram', 'models']\n",
      "==========\n",
      "79\n",
      "['downstream', 'task']\n",
      "==========\n",
      "80\n",
      "['log', '-', 'linear', 'models']\n",
      "==========\n",
      "81\n",
      "['early', 'stopping']\n",
      "==========\n",
      "82\n",
      "['binary', 'task']\n",
      "['binary', 'task']\n",
      "==========\n",
      "83\n",
      "['non', '-', 'parametric', 'approaches']\n",
      "==========\n",
      "84\n",
      "['semantic', 'representations']\n",
      "==========\n",
      "85\n",
      "['fixed', 'vocabulary', 'models']\n",
      "==========\n",
      "86\n",
      "['logistic', 'loss']\n",
      "==========\n",
      "87\n",
      "['CNN']\n",
      "['CNN', 'model']\n",
      "==========\n",
      "88\n",
      "['self', 'normalizing', 'partition', 'functions']\n",
      "==========\n",
      "89\n",
      "['training', 'recipes']\n",
      "==========\n",
      "90\n",
      "['chain', 'rule']\n",
      "==========\n",
      "91\n",
      "['inner', 'product']\n",
      "==========\n",
      "92\n",
      "['nearest', 'neighbor', 'embeddings']\n",
      "==========\n",
      "93\n",
      "['large', ',', 'regularized', 'LSTM', 'LM']\n",
      "==========\n",
      "94\n",
      "['full', 'Softmax']\n",
      "==========\n",
      "95\n",
      "['statistics', 'of', 'N', '-', 'grams']\n",
      "==========\n",
      "96\n",
      "['computational', 'complexity']\n",
      "==========\n",
      "97\n",
      "['video', 'generation']\n",
      "==========\n",
      "98\n",
      "['LMs']\n",
      "['LM']\n",
      "==========\n",
      "99\n",
      "['Noise', 'Contrastive', 'Estimation']\n",
      "==========\n",
      "100\n",
      "['asynchronous', 'gradient', 'updates']\n",
      "==========\n",
      "101\n",
      "['pre', '-', 'processing']\n",
      "==========\n",
      "102\n",
      "['complex', 'vision', 'models']\n",
      "==========\n",
      "103\n",
      "['Natural', 'Language', 'Processing']\n",
      "==========\n",
      "104\n",
      "['1', '-', 'd', 'CNN']\n",
      "==========\n",
      "105\n",
      "['Bayes', 'rule']\n",
      "==========\n",
      "106\n",
      "['BLEU', 'score']\n",
      "==========\n",
      "107\n",
      "['model', 'predictions']\n",
      "==========\n",
      "108\n",
      "['training', 'and', 'inference', 'time']\n",
      "==========\n",
      "109\n",
      "['TensorFlow', 'system']\n",
      "==========\n",
      "110\n",
      "['embedding', 'layer']\n",
      "==========\n",
      "111\n",
      "['Deep', 'Learning']\n",
      "==========\n",
      "112\n",
      "['multiclass', 'loss']\n",
      "==========\n",
      "113\n",
      "['128', '-', 'dim', 'correction']\n",
      "==========\n",
      "114\n",
      "['word', 'embeddings']\n",
      "['word', 'embeddings']\n",
      "['word', 'embedding']\n",
      "['Word', 'Embeddings']\n",
      "['word', 'embedding', 'term']\n",
      "==========\n",
      "115\n",
      "['gating', 'mechanism']\n",
      "==========\n",
      "116\n",
      "['Regularization', 'Importance']\n",
      "==========\n",
      "117\n",
      "['parsing']\n",
      "==========\n",
      "118\n",
      "['Softmax', 'loss']\n",
      "==========\n",
      "119\n",
      "['character', 'Convolutional', 'Neural', 'Networks']\n",
      "==========\n",
      "120\n",
      "['IS']\n",
      "['IS']\n",
      "['IS']\n",
      "==========\n",
      "121\n",
      "['word', '-', 'level', 'Softmax', 'layer']\n",
      "==========\n",
      "122\n",
      "['cross', 'entropy', 'loss']\n",
      "==========\n",
      "123\n",
      "['distributed', 'setting']\n",
      "==========\n",
      "124\n",
      "['conditional', 'language', 'models']\n",
      "==========\n",
      "125\n",
      "['modeling', 'language']\n",
      "==========\n",
      "126\n",
      "['large', 'scale', 'RNN', '-', 'based', 'LMs']\n",
      "==========\n",
      "127\n",
      "['NN', '-', 'based', 'LMs']\n",
      "==========\n",
      "128\n",
      "['2048', 'unit', 'LSTM']\n",
      "==========\n",
      "129\n",
      "['Count', '-', 'based', 'approaches']\n",
      "==========\n",
      "130\n",
      "['text', 'summarization']\n",
      "['text', 'summarization']\n",
      "==========\n",
      "131\n",
      "['large', 'scale', 'Softmax']\n",
      "==========\n",
      "132\n",
      "['large', 'scale', 'recurrent', 'neural', 'network', 'training']\n",
      "==========\n",
      "133\n",
      "['smoothing']\n",
      "==========\n",
      "134\n",
      "['2', '-', 'layer', 'LSTM']\n",
      "==========\n",
      "135\n",
      "['ML', 'community']\n",
      "==========\n",
      "136\n",
      "['bottleneck', 'linear', 'layer']\n",
      "==========\n",
      "137\n",
      "['regular', 'Softmax']\n",
      "==========\n",
      "138\n",
      "['small', 'character', 'CNNs']\n",
      "==========\n",
      "139\n",
      "['max', '-', 'pooling']\n",
      "==========\n",
      "140\n",
      "['human', 'language']\n",
      "==========\n",
      "141\n",
      "['parametrized', 'neural', 'network']\n",
      "==========\n",
      "142\n",
      "['Softmax', 'non', '-', 'linearity']\n",
      "==========\n",
      "143\n",
      "['sequence', '-', 'to', '-', 'sequence', 'models']\n",
      "==========\n",
      "144\n",
      "['Penn', 'Tree', 'Bank']\n",
      "Linked\n",
      "==========\n",
      "145\n",
      "['small', 'tasks']\n",
      "==========\n",
      "146\n",
      "['word', '-', 'level', 'LSTM', 'hidden', 'state']\n",
      "==========\n",
      "147\n",
      "['2', '-', 'layer', 'highway', 'network']\n",
      "==========\n",
      "148\n",
      "['bidirectional', 'LSTMs']\n",
      "==========\n",
      "149\n",
      "['Recurrent', 'Neural', 'Networks', 'based', 'LMs']\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "doc = documents['02b3d1d162080d9aefd3fc30a0bcc9a843073b5d']\n",
    "for c, spans in doc['predicted_clusters'].items() :\n",
    "    print(c)\n",
    "    for s, e in spans :\n",
    "        print(doc['words'][s:e])\n",
    "    if c in doc['linked_clusters'] :\n",
    "        print(\"Linked\")\n",
    "        \n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
